{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kernel_utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from numpy import linalg as LA\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/Xtr1_mat50.csv', sep=' ', header=None)\n",
    "Y = pd.read_csv('data/Ytr1.csv', sep=',', header=0)\n",
    "X_t = pd.read_csv('data/Xte1_mat50.csv', sep=' ', header=None)\n",
    "# Y_test = pd.read_csv('data/Yte0.csv', sep=',', header=0)\n",
    "Y.columns = [\"idx\", \"bound\"]\n",
    "Y = Y.drop([\"idx\"], axis=1)\n",
    "# Y_test.columns = [\"idx\", \"bound\"]\n",
    "# Y_test = Y_test.drop([\"idx\"], axis=1)\n",
    "\n",
    "X_raw = pd.read_csv('data/Xtr1.csv', sep=' ', header=None)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAA', 'AAC', 'AAT', 'AAG', 'ACA', 'ACC', 'ACT', 'ACG', 'ATA', 'ATC', 'ATT', 'ATG', 'AGA', 'AGC', 'AGT', 'AGG', 'CAA', 'CAC', 'CAT', 'CAG', 'CCA', 'CCC', 'CCT', 'CCG', 'CTA', 'CTC', 'CTT', 'CTG', 'CGA', 'CGC', 'CGT', 'CGG', 'TAA', 'TAC', 'TAT', 'TAG', 'TCA', 'TCC', 'TCT', 'TCG', 'TTA', 'TTC', 'TTT', 'TTG', 'TGA', 'TGC', 'TGT', 'TGG', 'GAA', 'GAC', 'GAT', 'GAG', 'GCA', 'GCC', 'GCT', 'GCG', 'GTA', 'GTC', 'GTT', 'GTG', 'GGA', 'GGC', 'GGT', 'GGG']\n"
     ]
    }
   ],
   "source": [
    "# Construction of the proteine\n",
    "\n",
    "from itertools import product\n",
    "from string import ascii_lowercase\n",
    "base_azote = ['A', 'C', 'T', 'G']\n",
    "\n",
    "# Creation of all possible combinations\n",
    "dic_prot = [''.join(i) for i in product(base_azote, repeat = 3)]\n",
    "nb_feat = len(dic_prot)\n",
    "print(dic_prot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:32<00:00, 21.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1. ...,  4.  0.  1.]\n",
      " [ 3.  1.  0. ...,  3.  2.  3.]\n",
      " [ 0.  0.  0. ...,  0.  2.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1. ...,  3.  1.  3.]\n",
      " [ 0.  1.  0. ...,  2.  1.  1.]\n",
      " [ 4.  1.  0. ...,  4.  0.  3.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "k=3\n",
    "def k_spectre(seq, k=3):\n",
    "    \"\"\"\n",
    "    Combine all the k-successive\n",
    "    \"\"\"\n",
    "    k_seq = []\n",
    "    for i in range(len(seq)-k+1):\n",
    "        tmp = ''\n",
    "        for j in range(k):\n",
    "            tmp += seq[i+j]\n",
    "        k_seq.append(tmp)\n",
    "    return k_seq\n",
    "\n",
    "init_feat = pd.DataFrame(0, index=[0], columns=dic_prot)\n",
    "# init_feat.append(np.zeros(4**k))\n",
    "\n",
    "def count_kuplet(k_seq):\n",
    "    k = len(k_seq[0])\n",
    "    new_feat = init_feat.copy()\n",
    "    for kuplet in k_seq:\n",
    "        new_feat[kuplet] += 1.\n",
    "    return np.array(new_feat).reshape(4**k)\n",
    "\n",
    "def feature_exractor(X, k=3):\n",
    "    X_processed = []\n",
    "    for seq in tqdm(X[0]):\n",
    "        X_processed.append(count_kuplet(k_spectre(seq)))\n",
    "    \n",
    "    return np.array(X_processed)\n",
    "\n",
    "    \n",
    "test = feature_exractor(X_raw)    \n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64)\n"
     ]
    }
   ],
   "source": [
    "test2 = test[:100]\n",
    "print(test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(X, Y, percent=0.8):\n",
    "    \"\"\"\n",
    "    Preprocessing the data.\n",
    "        - Shuffle\n",
    "        - Divide data and labels\n",
    "        - centering\n",
    "        - add dimension to the data\n",
    "        - cut into a training dataset and a test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # Shuffle phase\n",
    "    np.random.RandomState(1)\n",
    "    tmp = np.concatenate((X, np.matrix(Y)), axis=1)\n",
    "    np.random.shuffle(tmp)\n",
    "    X_tmp = tmp[:, :X.shape[1]]\n",
    "\n",
    "    # changing the value to {-1,1}\n",
    "    Y_tmp = (Y - 0.5) * 2\n",
    "\n",
    "    # centering data\n",
    "    # X = X-np.mean(X, axis=0)\n",
    "\n",
    "    # Scaling data\n",
    "    # X = scale( X, axis=0, with_mean=True, with_std=True, copy=True )\n",
    "\n",
    "    # Add one dimension to your data points in order to account for\n",
    "    # the offset if your data is not centered.\n",
    "    X_tmp = np.concatenate((X_tmp, np.ones((X_tmp.shape[0], 1))), axis=1)\n",
    "\n",
    "    # Compute the training and the test set\n",
    "    n_training = int(percent  * Y.size)\n",
    "    X_train = X_tmp[:n_training]\n",
    "    Y_train = Y_tmp[:n_training]\n",
    "    X_test = X_tmp[n_training:]\n",
    "    Y_test = Y_tmp[n_training:]\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = preprocessing(X[:400], np.transpose(np.matrix(Y['bound'][:400])), percent=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "# test = np.asarray(test)\n",
    "K = np.dot(X_train, X_train.T)\n",
    "n = K.shape[0]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_svm_primal(K,y,lamb):\n",
    "    \"\"\"\n",
    "    Transform the primal Support Vector Machine (SVM)\n",
    "    problem into a quadratic problem\n",
    "    Args:\n",
    "        - K : Kernel of x\n",
    "        - Y : Target labels\n",
    "        - lamb : regularization parameter\n",
    "    Ouput:\n",
    "        - Q : semi-definite matrix (quadratic parameter)\n",
    "        |K   0 |\n",
    "        |0     0 |\n",
    "\n",
    "        - P : vector parameter in the minimization part\n",
    "        |0,...,0 , 1, ..., 1|^t / lamb\n",
    "\n",
    "        - A : matrix constraint\n",
    "        |-yK   -I |\n",
    "        |0     -I |\n",
    "\n",
    "        - b : vector constraint\n",
    "        |-1,...,-1 , 0, ..., 0|^t\n",
    "\n",
    "    \"\"\"\n",
    "    K = np.matrix(K, dtype=np.float)\n",
    "    y = np.array(y, dtype=np.float)\n",
    "\n",
    "    # number of data\n",
    "    n = y.size\n",
    "\n",
    "    # Verify the shape of the data\n",
    "    try:\n",
    "        assert K.shape[0] == n\n",
    "    except AssertionError:\n",
    "        print(\"K and Y must have the same length\")\n",
    "        exit(1)\n",
    "\n",
    "    A1 = np.concatenate((-np.transpose(np.multiply(K, y)), -np.eye(n)), axis=1)\n",
    "    A2 = np.concatenate((np.zeros((n,n)), -np.eye(n)), axis=1)\n",
    "    A = np.concatenate((A1, A2), axis=0)\n",
    "\n",
    "    Q1 = np.concatenate((K, np.zeros((n,n))), axis=1)\n",
    "    Q2 = np.zeros((n, 2*n))\n",
    "    Q = lamb * np.concatenate((Q1, Q2), axis=0)\n",
    "\n",
    "    p = np.concatenate((np.zeros(n), np.ones(n)), axis=0) / n\n",
    "\n",
    "    b = np.concatenate((-np.ones(n), np.zeros(n)), axis=0)\n",
    "\n",
    "\n",
    "    return Q, p, A, b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0417e-02  1.0000e+00  2e+02  1e+00  1e+03\n",
      " 1:  9.6963e-01 -1.8915e+00  3e+00  1e-02  1e+01\n",
      " 2:  2.4580e-01 -1.2181e-02  3e-01  1e-04  1e-01\n",
      " 3:  2.4820e-03 -9.8424e-05  3e-03  1e-06  1e-03\n",
      " 4:  2.4820e-05 -9.8187e-07  3e-05  1e-08  1e-05\n",
      " 5:  2.4830e-07 -9.8226e-09  3e-07  1e-10  1e-07\n",
      "Terminated (singular KKT matrix).\n"
     ]
    }
   ],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "\n",
    "Q, p, A, b = transform_svm_primal(K,Y_train, 0.01)\n",
    "\n",
    "Q = matrix(2*Q)\n",
    "p = matrix(p)\n",
    "G = matrix(A)\n",
    "h = matrix(b)\n",
    "A = matrix(np.matrix(np.repeat(0.0, 2*n)))\n",
    "b = matrix(0.0)\n",
    "sol=solvers.qp(Q, p, G, h) # A, b)\n",
    "# print(sol['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 1)\n"
     ]
    }
   ],
   "source": [
    "w = np.array(sol['x'])\n",
    "print(np.array(w).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192,)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(0.0, 2*n).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -7.80867961e-15  -5.06435694e-15  -4.61161834e-15  -4.00950488e-15\n",
      "  -4.00908780e-15  -3.56429366e-15  -3.17175331e-15  -2.81535955e-15\n",
      "  -2.59962579e-15  -2.45059245e-15  -2.30021896e-15  -1.96121353e-15\n",
      "  -1.91445610e-15  -1.87038667e-15  -1.62057330e-15  -1.39231394e-15\n",
      "  -1.29131963e-15  -8.45333840e-16  -5.90172117e-16  -4.67250006e-16\n",
      "  -4.64945835e-16  -2.31635458e-16  -1.62515987e-16   6.37365589e-17\n",
      "   2.48749398e-16   3.34694063e-16   5.60130276e-16   7.20875239e-16\n",
      "   1.05695231e-15   1.10040163e-15   1.34944247e-15   1.72667435e-15\n",
      "   1.74214579e-15   1.74297644e-15   1.82101168e-15   2.29722004e-15\n",
      "   2.44123065e-15   2.82691886e-15   2.89013654e-15   3.23727390e-15\n",
      "   3.35301799e-15   3.92264614e-15   4.05607812e-15   4.41414867e-15\n",
      "   4.82480895e-15   1.01384912e-14   6.61745726e-04   8.32160657e-04\n",
      "   1.07979121e-03   1.33671548e-03   1.44606188e-03   1.59887301e-03\n",
      "   2.17873917e-03   2.82677738e-03   2.98327087e-03   3.14869977e-03\n",
      "   3.69411858e-03   4.11633440e-03   4.65036787e-03   5.18009871e-03\n",
      "   5.37852392e-03   5.67609983e-03   6.45720511e-03   6.79699229e-03\n",
      "   7.44779028e-03   8.12182584e-03   8.49909120e-03   9.45582657e-03\n",
      "   1.04188949e-02   1.10192943e-02   1.22764339e-02   1.42576197e-02\n",
      "   1.47867242e-02   1.66998964e-02   1.79534195e-02   1.90399262e-02\n",
      "   1.92658199e-02   2.05607314e-02   2.17474021e-02   2.41562947e-02\n",
      "   2.59367750e-02   2.77274768e-02   2.84929931e-02   3.17272764e-02\n",
      "   3.21347885e-02   3.68741005e-02   4.08004943e-02   4.49767110e-02\n",
      "   5.24333183e-02   6.41520979e-02   6.81317822e-02   7.59240730e-02\n",
      "   8.81469243e-02   1.82083870e-01   2.24187994e-01   9.81176653e+01]\n"
     ]
    }
   ],
   "source": [
    "w,v = np.linalg.eigh(K)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "w,v = np.linalg.eigh(np.dot(A.T, A))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cvxopt.base.matrix' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-368-431539bf4175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'cvxopt.base.matrix' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (160,160) and (80,) not aligned: 160 (dim 1) != 80 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-8ed2464bcaf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (160,160) and (80,) not aligned: 160 (dim 1) != 80 (dim 0)"
     ]
    }
   ],
   "source": [
    "print(np.dot(A, w_0) - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x,t,Q,p,A,b):\n",
    "    \"\"\"\n",
    "    Compute the fonction value\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=np.float)\n",
    "    Q = np.matrix(Q, dtype=np.float)\n",
    "    p = np.array(p, dtype=np.float)\n",
    "    A = np.matrix(A, dtype=np.float)\n",
    "    b = np.array(b, dtype=np.float)\n",
    "\n",
    "    phit = (0.5*x.dot(Q).dot(x) + p.dot(x))\n",
    "\n",
    "    phit = t*phit\n",
    "\n",
    "    tmp = b - A.dot(x)\n",
    "    tst = tmp < 0\n",
    "    # print(\"negatif dans le log\")\n",
    "    print(np.sum(tst)<1)\n",
    "    tmp = np.log(tmp)\n",
    "\n",
    "    phit = np.array(phit - np.sum(tmp))[0][0]\n",
    "    return phit\n",
    "\n",
    "def grad(x,t,Q,p,A,b):\n",
    "    \"\"\"\n",
    "    Compute the gradient of phit\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=np.float)\n",
    "    Q = np.matrix(Q, dtype=np.float)\n",
    "    p = np.array(p, dtype=np.float)\n",
    "    A = np.matrix(A, dtype=np.float)\n",
    "    b = np.array(b, dtype=np.float)\n",
    "\n",
    "    gradt = Q.dot(x) + p\n",
    "    gradt = t * gradt\n",
    "\n",
    "    tmp = b - A.dot(x)\n",
    "    tmp = 1./tmp\n",
    "    gradt = np.array(gradt + tmp.dot(A))[0]\n",
    "    return gradt\n",
    "\n",
    "\n",
    "def hess(x,t,Q,p,A,b):\n",
    "    \"\"\"\n",
    "    Compute the Hessian of phit\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=np.float)\n",
    "    Q = np.matrix(Q, dtype=np.float)\n",
    "    p = np.array(p, dtype=np.float)\n",
    "    A = np.matrix(A, dtype=np.float)\n",
    "    b = np.array(b, dtype=np.float)\n",
    "\n",
    "    hesst = t*Q\n",
    "    tmp = b - A.dot(x)\n",
    "    tmp = 1./np.square(tmp)\n",
    "    tmp = np.diag(np.array(tmp)[0])\n",
    "    tmp = (A.T).dot(tmp).dot(A)\n",
    "    # print(\"est ce que le terme de barriere est positif?\")\n",
    "    print(np.all(np.linalg.eigvals(np.dot(A.T, A)) >= -0.001))\n",
    "    hesst = hesst + tmp\n",
    "\n",
    "    return hesst\n",
    "\n",
    "\n",
    "def dampedNewtonStep(x,f,g,h):\n",
    "    \"\"\"\n",
    "    Compute the damped Newton step at point x\n",
    "    Args:\n",
    "        - x : point where the Newton step will be computed\n",
    "        - f : the value function\n",
    "        - g : the gradient function\n",
    "        - h : the hessian function\n",
    "    Ouput:\n",
    "        - x_new : the damped Newton step at point x\n",
    "        - lamdat2/2 : the estimated gap before the minimum\n",
    "    \"\"\"\n",
    "    phit = f(x)\n",
    "    gradt = np.array(g(x), dtype=np.float)\n",
    "    hesst = np.matrix(h(x), dtype=np.float)\n",
    "    # print(hesst.shape)\n",
    "    hesst_inv = np.linalg.inv(hesst)\n",
    "    # print(hesst_inv)\n",
    "    \n",
    "    # print(\"est ce que l'inverse est positif ? \")\n",
    "    print(np.all(np.linalg.eigvals(hesst_inv) >= -0.001))\n",
    "\n",
    "\n",
    "    lambdat2 = np.array(gradt.dot(hesst_inv).dot(gradt))\n",
    "    # print(lambdat2)\n",
    "    # if lambdat2 < 0:\n",
    "        # print(lambdat2)\n",
    "     #    print('probleme pour lambda (devrait etre positif)')\n",
    "    # else :\n",
    "    #     print('ok pour lambda')\n",
    "    coef = (1.+np.sqrt(lambdat2))\n",
    "    coef = 1./coef\n",
    "    x_new = np.array(x - coef * hesst_inv.dot(gradt))[0]\n",
    "    # print(\"ESPION3\")\n",
    "\n",
    "    return x_new, lambdat2/2\n",
    "\n",
    "\n",
    "\n",
    "def dampedNewton(x0,f,g,h,tol,Tmax=20):\n",
    "    \"\"\"\n",
    "    Implement the damped Newton algorithm\n",
    "    Args:\n",
    "        - x0 : initial point\n",
    "        - f : the value function to minimize\n",
    "        - g : the gradient function\n",
    "        - h : the hessian function\n",
    "        - tol : the threshold (smaller than 0.3819660112501051)\n",
    "        - Tmax : maximum number of iteration\n",
    "    Ouput:\n",
    "        - xstar : the point tol-minimizing f\n",
    "        - xhist : the history of damped step\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert tol < 0.3819660112501051\n",
    "    except AssertionError:\n",
    "        print(\"The threshold in dampedNewton must be smaller \")\n",
    "        exit(1)\n",
    "    xstar, gap = dampedNewtonStep(x0,f,g,h)\n",
    "    xhist = [x0, xstar]\n",
    "    phi_w_hist = [f(x0), f(xstar)]\n",
    "    it = 1\n",
    "    while(gap>tol and it<Tmax):\n",
    "        it +=1\n",
    "        xstar, gap = dampedNewtonStep(xstar,f,g,h)\n",
    "        # print(\"ESPION2\")\n",
    "        phi_w_hist.append(f(xstar))\n",
    "        xhist.append(xstar)\n",
    "    xhist = np.array(xhist)\n",
    "\n",
    "    return xstar, xhist, phi_w_hist\n",
    "\n",
    "\n",
    "\n",
    "def barr_method(Q,p,A,b,x_0,mu,tol):\n",
    "    \"\"\"\n",
    "    Solve the Quadratic problem using damped Newton method\n",
    "    Args:\n",
    "        - Q : semi-definite matrix (quadratic parameter)\n",
    "        - P : vector parameter in the minimization part\n",
    "        - A : matrix constraint\n",
    "        - b : vector constraint\n",
    "        - x_0 : inital state\n",
    "        - mu :  increment of the barrier parameter\n",
    "        - tol : the threshold\n",
    "    Ouput:\n",
    "        - x_sol : the argument minimizing the quadratic problem\n",
    "        - x_hist : the history of step\n",
    "    \"\"\"\n",
    "    t = mu\n",
    "    x_sol = x_0\n",
    "    x_hist = np.matrix(x_sol)\n",
    "    phi_w_hist = []\n",
    "    it=0\n",
    "    while(mu/t > tol):\n",
    "        it+=1\n",
    "        # if(it%100 == 0):\n",
    "        print(\"we want {} to be less than {}\".format(mu/t, tol))\n",
    "        f = lambda x: phi(x,t,Q,p,A,b) ;\n",
    "        g = lambda x: grad(x,t,Q,p,A,b) ;\n",
    "        h = lambda x: hess(x,t,Q,p,A,b) ;\n",
    "        x_sol, xhist_tmp, ph_w_tmp = dampedNewton(x_sol,f,g,h,tol)\n",
    "        # print(\"ESPION1\")\n",
    "        x_hist = np.concatenate((x_hist, xhist_tmp), axis = 0)\n",
    "        phi_w_hist.append(ph_w_tmp)\n",
    "        t = mu*t\n",
    "\n",
    "    #phi_w_hist.append(f(x_sol))\n",
    "    return x_sol, x_hist, phi_w_hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_0 = np.append(np.repeat(0., K.shape[0]), np.repeat(2., K.shape[0]))\n",
    "# w, w_hist, phi_w_hist = barr_method(Q,p,A,b,w_0,1.2,0.1)\n",
    "# w_0 = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we want 1.0 to be less than 0.001\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "we want 0.1 to be less than 0.001\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "we want 0.01 to be less than 0.001\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "w, w_hist, phi_w_hist = barr_method(Q,p,A,b,w_0,mu = 10.,tol = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_predict = lambda x: \n",
    "tmp = np.dot(X_test, np.transpose(X_train))\n",
    "result = np.dot(tmp, w[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = result > 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True]], dtype=bool)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = (Y_test == (Y_predicted - 0.5)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
       "          1., -1., -1.,  1., -1., -1., -1.]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose((Y_predicted - 0.5)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for testing : 2.1\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for testing : {}\".format(np.sum(Y_test == np.transpose(Y_predicted))/len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for testing : 0.4975\n",
      "accuracy for training : 0.575\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(C=.001, kernel='poly', degree=3)\n",
    "\n",
    "clf.fit(X_train, Y_train['bound'])\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_train_pred = clf.predict(X_train)\n",
    "print(\"accuracy for testing : {}\".format(np.sum(Y_test['bound'] == Y_pred)/len(Y_test)))\n",
    "print(\"accuracy for training : {}\".format(np.sum(Y_train_pred == Y_train['bound'])/len(Y_train)))\n",
    "# print(Y_train_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for testing : 0.5325\n",
      "accuracy for training : 0.584375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "clf = KernelRidge(alpha=.1)\n",
    "clf.fit(X_train, Y_train['bound'])\n",
    "Y_pred = clf.predict(X_test) > 0.5\n",
    "Y_train_pred = clf.predict(X_train) > 0.5\n",
    "print(\"accuracy for testing : {}\".format(np.sum(Y_test['bound'] == Y_pred)/len(Y_test)))\n",
    "print(\"accuracy for training : {}\".format(np.sum(Y_train_pred == Y_train['bound'])/len(Y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for testing : 0.495\n",
      "accuracy for training : 0.9175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=5, max_depth=None, min_samples_split=4, random_state=0)\n",
    "clf.fit(X_train, Y_train['bound'])\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_train_pred = clf.predict(X_train)\n",
    "print(\"accuracy for testing : {}\".format(np.sum(Y_test['bound'] == Y_pred)/len(Y_test)))\n",
    "print(\"accuracy for training : {}\".format(np.sum(Y_train_pred == Y_train['bound'])/len(Y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for testing : 0.4775\n",
      "accuracy for training : 0.731875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=5, learning_rate=.1, max_depth=5, random_state=0)\n",
    "clf.fit(X_train, Y_train['bound'])\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_train_pred = clf.predict(X_train)\n",
    "print(\"accuracy for testing : {}\".format(np.sum(Y_test['bound'] == Y_pred)/len(Y_test)))\n",
    "print(\"accuracy for training : {}\".format(np.sum(Y_train_pred == Y_train['bound'])/len(Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1600/1600 [==============================] - 1s 691us/step - loss: 0.7011 - acc: 0.4806\n",
      "Epoch 2/20\n",
      "1600/1600 [==============================] - 1s 359us/step - loss: 0.6986 - acc: 0.4881\n",
      "Epoch 3/20\n",
      "1600/1600 [==============================] - 1s 376us/step - loss: 0.6984 - acc: 0.5119\n",
      "Epoch 4/20\n",
      "1600/1600 [==============================] - 1s 376us/step - loss: 0.6970 - acc: 0.4963\n",
      "Epoch 5/20\n",
      "1600/1600 [==============================] - 1s 391us/step - loss: 0.6964 - acc: 0.5144 0s - loss: 0.6940 -\n",
      "Epoch 6/20\n",
      "1600/1600 [==============================] - 1s 370us/step - loss: 0.6972 - acc: 0.4838\n",
      "Epoch 7/20\n",
      "1600/1600 [==============================] - 1s 376us/step - loss: 0.6965 - acc: 0.4988\n",
      "Epoch 8/20\n",
      "1600/1600 [==============================] - 1s 413us/step - loss: 0.6959 - acc: 0.5113 0s - loss: 0.6950 - \n",
      "Epoch 9/20\n",
      "1600/1600 [==============================] - 1s 381us/step - loss: 0.6959 - acc: 0.5019\n",
      "Epoch 10/20\n",
      "1600/1600 [==============================] - 1s 450us/step - loss: 0.6946 - acc: 0.5200\n",
      "Epoch 11/20\n",
      "1600/1600 [==============================] - 1s 510us/step - loss: 0.6960 - acc: 0.4963\n",
      "Epoch 12/20\n",
      "1600/1600 [==============================] - 1s 571us/step - loss: 0.6959 - acc: 0.5069\n",
      "Epoch 13/20\n",
      "1600/1600 [==============================] - 1s 471us/step - loss: 0.6956 - acc: 0.4875\n",
      "Epoch 14/20\n",
      "1600/1600 [==============================] - 1s 414us/step - loss: 0.6966 - acc: 0.4950\n",
      "Epoch 15/20\n",
      "1600/1600 [==============================] - 1s 407us/step - loss: 0.6936 - acc: 0.5188\n",
      "Epoch 16/20\n",
      "1600/1600 [==============================] - 1s 424us/step - loss: 0.6950 - acc: 0.4988\n",
      "Epoch 17/20\n",
      "1600/1600 [==============================] - 1s 399us/step - loss: 0.6947 - acc: 0.5044\n",
      "Epoch 18/20\n",
      "1600/1600 [==============================] - 1s 526us/step - loss: 0.6952 - acc: 0.5113\n",
      "Epoch 19/20\n",
      "1600/1600 [==============================] - 1s 675us/step - loss: 0.6940 - acc: 0.5031\n",
      "Epoch 20/20\n",
      "1600/1600 [==============================] - 1s 422us/step - loss: 0.6962 - acc: 0.4756\n",
      "accuracy for testing : bound    0.5\n",
      "dtype: float64\n",
      "accuracy for training : bound    0.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=50, activation='sigmoid', kernel_initializer='random_uniform'))\n",
    "model.add(Dense(50, activation='sigmoid', kernel_initializer='random_uniform'))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# am = Adam(lr=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train['bound'], epochs=20, batch_size=5)\n",
    "\n",
    "# clf.fit(X_train, )\n",
    "Y_pred = model.predict(X_test)>0.5\n",
    "Y_train_pred = model.predict(X_train)>0.5\n",
    "print(\"accuracy for testing : {}\".format(np.sum(Y_test == Y_pred)/len(Y_test)))\n",
    "print(\"accuracy for training : {}\".format(np.sum(Y_train_pred == Y_train)/len(Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon en fait j'ai l'impression que a marche pas de ouf cette représentation des ACTG... Faut qu'on trouve notre propre truc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAA', 'AAC', 'AAT', 'AAG', 'ACA', 'ACC', 'ACT', 'ACG', 'ATA', 'ATC', 'ATT', 'ATG', 'AGA', 'AGC', 'AGT', 'AGG', 'CAA', 'CAC', 'CAT', 'CAG', 'CCA', 'CCC', 'CCT', 'CCG', 'CTA', 'CTC', 'CTT', 'CTG', 'CGA', 'CGC', 'CGT', 'CGG', 'TAA', 'TAC', 'TAT', 'TAG', 'TCA', 'TCC', 'TCT', 'TCG', 'TTA', 'TTC', 'TTT', 'TTG', 'TGA', 'TGC', 'TGT', 'TGG', 'GAA', 'GAC', 'GAT', 'GAG', 'GCA', 'GCC', 'GCT', 'GCG', 'GTA', 'GTC', 'GTT', 'GTG', 'GGA', 'GGC', 'GGT', 'GGG']\n"
     ]
    }
   ],
   "source": [
    "# Construction of the proteine\n",
    "\n",
    "from itertools import product\n",
    "from string import ascii_lowercase\n",
    "base_azote = ['A', 'C', 'T', 'G']\n",
    "\n",
    "# Creation of all possible combinations\n",
    "dic_prot = [''.join(i) for i in product(base_azote, repeat = 3)]\n",
    "nb_feat = len(dic_prot)\n",
    "print(dic_prot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    CGGGCCTCCTCCAGGCTCAGAATCGACCCCCCCCCATCCTGATAGA...\n",
      "1    CTCCGCCCGCACTTCCGTCTGGACGCGAAGGCGTCACCGGGCGCGC...\n",
      "2    GGTGTCTAGTCACATTACCTGAGATCTGACATTTTTATCCGTCTGA...\n",
      "3    CGGCCTCCCTACCCCAGCCTCGCTCTGGGCGCCGTGACGTCACCTC...\n",
      "4    GTTTGAATGGTGATCACGTGACGGGGCGGTGACGTCACCCGCCCTG...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_raw = pd.read_csv('data/Xtr1.csv', sep=' ', header=None)\n",
    "# test on one sequence\n",
    "seq = X_raw[0][:5]\n",
    "# print(len(seq))\n",
    "print(seq)\n",
    "# print(Y['bound'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 59/2000 [00:02<01:29, 21.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-30aa6334f00d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_exractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-30aa6334f00d>\u001b[0m in \u001b[0;36mfeature_exractor\u001b[0;34m(X, k)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mX_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mX_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_kuplet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_spectre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-30aa6334f00d>\u001b[0m in \u001b[0;36mcount_kuplet\u001b[0;34m(k_seq)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mnew_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkuplet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnew_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkuplet\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.4/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# this makes sure that we are aligned like the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.4/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right, name, na_op)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_na_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         return construct_result(\n\u001b[1;32m    741\u001b[0m             \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.4/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.4/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.4/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0muse_numexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_bool_arith_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.4/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b, **eval_kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "k=3\n",
    "\n",
    "def k_spectre(seq, k=3):\n",
    "    \"\"\"\n",
    "    Combine all the k-successive\n",
    "    \"\"\"\n",
    "    k_seq = []\n",
    "    for i in range(len(seq)-k+1):\n",
    "        tmp = ''\n",
    "        for j in range(k):\n",
    "            tmp += seq[i+j]\n",
    "        k_seq.append(tmp)\n",
    "    return k_seq\n",
    "\n",
    "init_feat = pd.DataFrame(0, index=[0], columns=dic_prot)\n",
    "# init_feat.append(np.zeros(4**k))\n",
    "\n",
    "def count_kuplet(k_seq):\n",
    "    k = len(k_seq[0])\n",
    "    new_feat = init_feat.copy()\n",
    "    for kuplet in k_seq:\n",
    "        new_feat[kuplet] += 1.\n",
    "    return np.array(new_feat).reshape(4**k)\n",
    "\n",
    "def feature_exractor(X, k=3):\n",
    "    X_processed = []\n",
    "    for seq in tqdm(X[0]):\n",
    "        X_processed.append(count_kuplet(k_spectre(seq)))\n",
    "    \n",
    "    return X_processed\n",
    "\n",
    "    \n",
    "test = feature_exractor(X_raw)    \n",
    "test = np.array(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.asarray(test)\n",
    "K = np.dot(test, test.T)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, d = test.shape\n",
    "lamb = 0.5\n",
    "\n",
    "test2 = np.matrix(test)\n",
    "\n",
    "A1 = np.concatenate((-K, -np.eye(N)), axis=1)\n",
    "A2 = np.concatenate((np.zeros((N,N)), -np.eye(N)), axis=1)\n",
    "A = np.concatenate((A1, A2), axis=0)\n",
    "\n",
    "Q1 = np.concatenate((K, np.zeros((N,N))), axis=1)\n",
    "Q2 = np.zeros((N, 2*N))\n",
    "Q = np.concatenate((Q1, Q2), axis=0)\n",
    "\n",
    "p = np.concatenate((np.zeros(N), np.ones(N)), axis=0) / lamb\n",
    "\n",
    "b = np.concatenate((-np.ones(N), np.zeros(N)), axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.multiply(K,)\n",
    "Y_tmp = np.array(Y['bound'])\n",
    "Y_tmp = (Y_tmp - 0.5) * 2\n",
    "tmp_test = np.multiply(Y_tmp,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-321.,  199.,  -95., ...,  157., -176., -179.],\n",
       "       [-199.,  323., -106., ...,  205., -167., -159.],\n",
       "       [ -95.,  106., -299., ...,  132., -153., -132.],\n",
       "       ..., \n",
       "       [-157.,  205., -132., ...,  249., -141., -152.],\n",
       "       [-176.,  167., -153., ...,  141., -283., -128.],\n",
       "       [-179.,  159., -132., ...,  152., -128., -297.]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 4000)\n"
     ]
    }
   ],
   "source": [
    "print(Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we want 1.0 to be less than 0.3\n",
      "we want 0.9090909090909091 to be less than 0.3\n",
      "we want 0.8264462809917353 to be less than 0.3\n",
      "we want 0.7513148009015775 to be less than 0.3\n",
      "we want 0.6830134553650704 to be less than 0.3\n",
      "we want 0.6209213230591548 to be less than 0.3\n",
      "we want 0.5644739300537771 to be less than 0.3\n",
      "we want 0.5131581182307065 to be less than 0.3\n",
      "we want 0.4665073802097331 to be less than 0.3\n",
      "we want 0.42409761837248455 to be less than 0.3\n",
      "we want 0.38554328942953137 to be less than 0.3\n",
      "we want 0.35049389948139215 to be less than 0.3\n",
      "we want 0.31863081771035645 to be less than 0.3\n",
      "etape3\n"
     ]
    }
   ],
   "source": [
    "w_value_hist = []\n",
    "ac_range = []\n",
    "ac_range2 = []\n",
    "# for tau = 0.0001 et tol = 0.1 on obtient acc = 59.5\n",
    "# for tau = [0.005, 0.01, 0.05] on obtient : [53.5, 49.5, 46.5]\n",
    "\n",
    "taurange = [0.0001] # , 0.1, 0.15, 0.2, 0.3]\n",
    "\n",
    "for tau in taurange:\n",
    "    acc_range=[]\n",
    "    it = 0\n",
    "    # while(it < 20):\n",
    "    # for it in tqdm(range(0)):\n",
    "    X_train, Y_train, X_test, Y_test = preprocessing(X, Y)\n",
    "    mu = 1.1\n",
    "    w, w_hist, phi_w_hist = SVM_vector(X_train, Y_train['bound'], tau, mu, tol=0.3)\n",
    "    print('etape3')\n",
    "    w_value_hist.append(w)\n",
    "    Y_train_predicted, acc_train = predict(w, X_train, Y_train['bound'])\n",
    "    Y_predicted, acc = predict(w, X_test, Y_test['bound'])\n",
    "    \n",
    "    ac_range.append(acc_train)\n",
    "    ac_range2.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50.0]\n"
     ]
    }
   ],
   "source": [
    "print(ac_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50.0]\n"
     ]
    }
   ],
   "source": [
    "print(ac_range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEOCAYAAACJlmBtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl0FOeZ7/Hvq51FCwIBAqkBgTFm\nRwgRO4kd22A73o0xWHjJvXOD8GSZTG4SnGUyycxkEptkJplMNiAz5x47RoDBW+JsVuwk9mSCkATY\nLLYBAS2xb5LYQdJz/+jCIxOW1tJd3erf5xwduqq7qh8SH3566q16X2dmiIiIJPldgIiIxAYFgoiI\nAAoEERHxKBBERARQIIiIiEeBICIigAJBREQ8CgQREQEUCCIi4knxu4COGDBggA0fPtzvMkRE4kpN\nTc0hM8u70ufiKhCGDx9OdXW132WIiMQV59yucD6nS0YiIgIoEERExKNAEBERQIEgIiIeBYKIiAAK\nBBER8SgQREQESJBAWBc8ylP/vdPvMkREYlpcPZjWWc+sCbK6toGCfr24acwgv8sREYlJCdEh/NM9\n4xk3JIvPVKxn24HjfpcjIhKTEiIQeqUls/iREtJSkih/qpqmU+f8LklEJOYkRCAADM3pxY8fnkrw\nyEn+dvk6WtvM75JERGJKwgQCQOmIXL5+9zhee+cg3/ntO36XIyISUxJiULm9hz8wjM17m/nx77dz\nTX4Wd08a4ndJIiIxIaE6hPO+ftc4pg3vx8JVG9i4u8nvckREYkJCBkJaShI/emgq/XqnseDpGg4d\nP+N3SSIivkvIQADIy0xnySMlHDp+hk88U8u51ja/SxIR8VXCBgLAhIJsFs2eSNWOI/zjzzf7XY6I\niK+iGgjOuSe9P8vb7Zvh/TwZzVrOu2fyUBZcX8TTf97FsjVBP0oQEYkJ0e4Qyp1z24E6CIUB8ICZ\nVQLFzrniKNcDwMLbxnDD6Dy+9tJGqnce8aMEERHfRTsQ5pvZSC8AMLNKM1vgvVdkZrVRrgeA5CTH\n9x+cQkG/3jz2s1r2NJ7yowwREV9FOxCKvMtDC9vv9LYXXOKYqMjuncrSR6dy+lwrC56u4fS5Vj/L\nERGJuqgGgpkt8rqD/t7lovf2AwucczkXHuOcK3fOVTvnqg8ePBjR+kYNzOR7cyezcU8TX1z9Jmaa\n3kJEEkfUAsH7h322t3mYULfQftygDii/8DgzW2JmJWZWkpeXF/E6Z4wdxOdmjuaF9Xv46es7Iv59\nIiKxIpodQjVQ6b0e6W3PAHK9fTl4g81+++SNo7h9wmC+9ast/OHdyHYlIiKxImqB4A0Yz/G6hO3e\n9hJCnUK595lV0arncpxzfHv2JEYPyuTTy2rZeeiE3yWJiESci6fr5CUlJVZdXR2176s/cpK7f/AG\n/fum8/wnriMzIzVq3y0i0l2cczVmVnKlzyX0k8pXUpjbmx8+VMyOQyf47IoNtGkNBRHpwRQIV3Dd\nyAF89Y5rqNyyn+9Vvut3OSIiEZNw6yF0xseuG86mPc18/9VtXJOfxUcn5PtdkohIt1OHEAbnHN+4\nbzxTAjl87tkNbNnb7HdJIiLdToEQpvSUZBY/PJXMjBTKn67m6ImzfpckItKtFAgdMDArg588PJX9\nTWf45LJaWrSGgoj0IAqEDpoS6Mc3Z03gT9sP88+/3OJ3OSIi3UaDyp0we2oBm/c085//tYOx+Vk8\nUFLod0kiIl2mDqGTvnz7GD44qj9feX4j64JH/S5HRKTLFAidlJKcxA/KihmUnc6Cp2vY33za75JE\nRLpEgdAF/fqksfTREo6fadEaCiIS9xQIXTRmcBb/OmcS6+sb+bsXNmoNBRGJWwqEbnDb+Hz+5uar\nWFXTwP/7006/yxER6RQFQjf525uvYubYQXzj5S38adshv8sREekwBUI3SUpyfHfuZIoG9OETy2qp\nP3LS75JERDpEgdCN+qansPTREtrajPlPVXPiTIvfJYmIhE2B0M2GD+jDD+YV8+7+Y3z+2Q0aZBaR\nuKFAiIDrR+fxpY9ew6827uMHr27zuxwRkbAoECLk4x8ewX1ThvIvr7zLK5v3+12OiMgVRTUQnHNP\nen+Wt9tX7v08Gc1aIs05x7dmTWBiQTafXbGerfuP+V2SiMhlRbtDKHfObQfqAJxzM4BKM1sCFHnb\nPUZGajKLH5lKRmoy85+qpunkOb9LEhG5pGgHwnwzG2lmld52EXA+BOq87R4lP7sXP3m4mN2Np/hU\nRS2tbRpkFpHYFO1AKHLOzXDOLQQwsyVedwBQDFRHuZ6oKBmeyz/eM57Xtx5i0a/f9rscEZGLimog\nmNkirzvo3/7ykHOuGKg1s9po1hNNZaUBHvnAMBb/sY4X1u32uxwRkb8QtUDwBo5ne5uHef/loRlm\n9vhljqt2zlUfPHgw4nVG0t/fNZbSEbk8vvpN3mpo8rscEZH3iWaHUA2cHzsY6W3jnCs3s0Xe678Y\nVPYuK5WYWUleXl7Uio2E1OQkfvxQMQP6plP+dDUHj53xuyQRkfdELRC8y0FzvC5hu5nVegHwpHNu\nu3MuIZYd6983ncWPTOXoybP89c9qONvS5ndJIiJA9McQlpjZqvMdgZlVmlk/786jfu3uPurRxg/N\n5tuzJ1G96yhfe2mT3+WIiACQ4ncBiequSUPYvLeZH/9+O+OGZPHwB4b5XZKIJDhNXeGjz99yNTde\nncfXX9rEmrrDfpcjIglOgeCj5CTHv5VNIdC/N594ppbdjaf8LklEEpgCwWdZGaksfbSEsy1tlD9V\nzamzrX6XJCIJSoEQA0bm9eXfyiazeW8zC1e/qTUURMQXCoQYcdOYQXzh1qv5+YY9LP5jnd/liEgC\nUiDEkL++YSR3TsznyV+/zWtvH/C7HBFJMAqEGOKcY9HsiVwzOIu/Wb6OuoPH/S5JRBKIAiHG9E5L\nYcmjU0lNTmL+U9U0n9YaCiISHQqEGFTQrzc/eqiYXYdP8rfL12sNBRGJCgVCjPpAUX++dtdYXn37\nAP/6yjt+lyMiCUBTV8Swhz8wjE17mvnha9u5Jj+LOycO8bskEenB1CHEMOcc/3DPOKYO68cXnn2T\nTXu0hoKIRI4CIcalpyTz44eLye6VSvlTNRw+rjUURCQyFAhxYGBmBksencrB42f45LJazrVqDQUR\n6X4KhDgxsSCHJ2ZN4M91R/jGLzb7XY6I9EAaVI4js4oL2LK3maWv72DskCzmTgv4XZKI9CDqEOLM\n47eN4cNXDeDvXthIza4jfpcjIj2IAiHOpCQn8e9lUxiS04sFT9eyt0lrKIhI9wgrEJxzH3fOZXX1\ny5xzT3p/ll+wv7ir504kOb3TWPpoCafOtvDY0zWcPqc1FESk68LtEJYAR51za51z/6cL4VDunNsO\nvDe/s3NuBvBsJ8+XsEYPyuS7cyezoaGJLz/3ltZQEJEuCysQzCwJmAvsAJbS+XCYb2Yjzayy3bkr\naRcQEr5bxg3mszNG89y63fzHGzv8LkdE4lzYYwhmtsrM5njhcCtQA3ybUDhUhRkORc65Gc65hV2o\nWdr59E2juG3cYL75yy28vvWg3+WISBzr7KByFfBboBJwQAn/0zn82jk3/GIHmdkiryPo710qki5K\nSnL8y5xJXDUwk08tW8euwyf8LklE4lTYgeCcG+6c+7xzbi1wlNB1/xxgAdCvXecwCvjJRY4vd87N\n9jYPA0Vhfm+5c67aOVd98KB+A76YPukpLH20BOdg/lPVHD/T4ndJIhKHwr3L6AiwHfgyoXGEOWaW\nbGa3mNlSM2uC98YDFgGlFzlNNaGOAmCkt31FZrbEzErMrCQvLy+cQxJSoH9vflBWzLYDx/ncyvW0\naQ0FEemgjtxlVGJmud44wurLfHYFMOLCnWZWC8zxuoTt3jbedkm77kE66UNXDeArd4zlN5v28/1X\nt/pdjojEmbCmrjCzLzrnspxzHzeznwI450YANwMrzay53WcvOUezmS25yL5VwKoOVy4X9VcfHM7m\nPc18r3IrYwZncdv4wX6XJCJxItxLRiOARmBxuzuJcgh1DnWXGkSW6HPO8c/3jWdSYQ6fW7med/Yd\n87skEYkT4V4yWgzUAqPOdwNmto7QAPIuLjKILP7JSE1m8cNT6Z2ewvynqmk8edbvkkQkDoQbCCXA\nN83sfU8/mVkd8C1gZncXJl0zODuDnzw8lX1Np/nUsnW0aA0FEbmCcAPhCBcZKPaMQE8ax6Spw/rx\njXvH88a2Qzzxq7f9LkdEYly4gbAaWOScu6/9TufcLOAJNCgcs+ZMK+R/XTecn76xg9U1DX6XIyIx\nLNy7jB53zuUAq51zRmiAOYfQU8qrzOxLEaxRuugrd1zDO/uO8aXn32LkwL5MLszxuyQRiUEdmcto\nAaEHyuYS6goeA0aa2ZwI1SbdJDU5iR8+VMzAzHQWPF3NgebTfpckIjGoQ3MZmdkOb5K7b3tPKO/w\nnk/4fKQKlO6R2yeNJY+U0Hyqhcd+VsOZFq2hICLvF/aayt54QRHQ/4K3igndhfSdbqxLImDskCy+\n88AkPrmslr9/YRNP3D8B55zfZYlIjAgrEJxzXyB0mWgHoVA46v3kAtmEJriTOHDHxHy27B3FD17b\nxrihWTx67XC/SxKRGBHuJaMFwBIzG0Vo7KDSzEaZWS6hkNBtp3Hk/84czYxrBvIPP9/Mf28/7Hc5\nIhIjwg2EIuAV7/UrhC4TnfdF4MnuLEoiKynJ8d25kxnevzefeKaG+iMn/S5JRGJAuIFQh/dgmve0\n8kjn3DDvvaO8PyAkDmRmpLL00RJa2ozyp2s4eVZrKIgkunAD4XfAl9s9mFYLPO5NarcAXTKKS0V5\nffn3sim8s6+ZLzz7JmZaQ0EkkYUVCN4zCK8SGj8AKPdebwdmA49HpDqJuI9cPZCFt43h5bf28qPf\nb/e7HBHxUbh3GWWZ2QPnt82s1jnXj9DtptWXWwNBYt+C64vYvKeZ7/z2HcYMzuTmawb5XZKI+CDc\nS0Y7nXPfbL/DzJrM7HcKg/jnnOPJ+ycybkgWn1m+nm0HtIaCSCIKNxCWAg845zIjWYz4p1daMosf\nKSE9JYn5T9XQdOqc3yWJSJSF+6TyGmAKoU5hBRcZRDYzPakc54bm9OLHD09l3tI/85nl6/iPj00j\nOUlPMoskChfOnSXOuSNX+IiZ2YVTWnS7kpISq66ujvTXJLxn1uziK89v5LEbRvLFj47xuxwR6SLn\nXI2ZlVzpc+HeZZR7hZ+wwsA596T3Z3m7fbOdczOccwvDOYdE3kPThzFveoCf/GE7L67f7Xc5IhIl\nHZrttBuUO+e2411ycs4VA5hZJdB4flv89/W7xjFteD8eX/0mG3frvgGRRBDubacrrvQZM5sbxqnm\nm1n71dXm8j9TYtQBMwg99CY+S0tJ4kcPTeWeH7xB+VPVvPTpDzGgb7rfZYlIBIXbIbiL/PQDHiA0\nbUW4TyoXXXB5KIfQes3nRXwcQsKXl5nO4kdKOHziLJ/4WS1nW9r8LklEIijcMYQ5F/m5hdD0103A\n2jDPs8i7PNTfOTcjnGOcc+XOuWrnXPXBgwfDOUS60YSCbBbNnkjVziP84y82+V2OiERQl8YQzKyR\n0DoJV5zt1PuHfba3eZjQDKqNhEIFQt3CX8zFbGZLzKzEzEry8vK6Uq500j2Th7LghiJ+9ucgy9YE\n/S5HRCKkOwaVjdA/7ldSDVR6r0d62yvaHVvU7n2JMQtvHcMNo/P42ksbWbvzSnchi0g8CndQedYl\n3ioCvkQYA8He/Efl3jMN282s1jt3iXf5qPH8Pok9yUmO7z84hXt/9F/89c9qeOlTH2JITi+/yxKR\nbhTug2mXG02sBR7w1kmIKD2Y5r9tB45x7w//xPABvVn12HVkpCb7XZKIXEF3P5iWdJmfkmiEgcSG\nUQMz+d7cyWza08wXV2sNBZGeJOwxBOdclnPu4+22hzvnPu6cy4pMaRKrZowdxOdmjuaF9XtY+rrW\nRhLpKcIKBOfcCEJ3BC1uFwD9gCVAnbdymiSQT944itsnDOaJX73NH97V7cAiPUG4HcJiQmMFo8ys\nGcDM1gGjgF3ATyJTnsQq5xzfnj2J0YMy+fSyWnYcOuF3SSLSReEGQgnwzQvHCsysDvgWMLO7C5PY\n1yc9haWPlpCc5Jj/VDXHTmsNBZF4Fm4gHAFGXOK9EYQ/dYX0MIW5vfnhQ8XsOHSCz65YT1ubBplF\n4lW4gbAaWOScu6/9Tu/5hCeAVRc9ShLCdSMH8NU7rqFyywG+V/mu3+WISCeF9WCamT3unMsBVjvn\njNAAcw6hSe5WmdmXIlijxIGPXTeczXub+f6r2xiTn8XtE/L9LklEOijcJTQxswXOuScIzW56fh6i\nSj2DIBAaZP6ne8ez9cBxPrdyA6nJSdw0ZqCW4BSJIx16DgG42cxWm9m3Cc07dLOeQ5Dz0lOSWfzw\nVAZkpjH/qWquX/Qa/1a5lb1Np/wuTUTCEO7UFSOA7YQmsutnZs3OuSlADaEB5xIz2xnJQkFTV8SL\nsy1tVG7ZT0VVkNe3HiLJwU1jBlJWGuAjV6trEIm2cKeuCDcQfktomur3zVnknCsCngUOmtltXag3\nLAqE+BM8fJLla4OsrG7g0PEz5GdnMKekkLnTCjU5nkiUdHcgHAE+bmbPXeS92cAKM4v4LGcKhPh1\nrrWN323Zz7Kqel7fehAHfOTqUNdw49V5pCRHe3lvkcQRbiCEO6is5xCkS1KTk7htfD63jc+n/shJ\nVqytZ2V1PfOfqmZQVjpzSwqZM62Qgn69/S5VJGGF2yE8CXwemG1mz7fbP4vQJaNF0bj1VB1Cz3Ku\ntY1X3z7A8qogv/fmQ7phdB5lpQFuGjOQVHUNIt2iWy8ZeSdcDMwnNLB84XMIc7pQa9gUCD1Xw9GT\nrKxuYOXaevY1n2ZgZvp7Yw2FueoaRLqi2wPBO+kIfHwOQYHQ87W0tvH7dw5SURXktXcOYMCHr8qj\nbFohM8YOUtcg0gkRCYTLfNlkM1vf5RNdgQIhsexpPMXK6npWrK1nb9NpBvRN54GSAh6cVsiw/n38\nLk8kbkQ8EJxzk4G5wGygqCN3GTnnFprZovOvCQ1K55rZkssdp0BITK1txh/ePcCyNfW8+vZ+2gw+\nNGoAZaUBZo4dRFqKugaRy+nuu4zOn3Q4sAAvBAiNIdQCX+zAOWYQmi57kfcaM1vlnHvSOVfkTakt\n8p7kJMdNYwZx05hB7Gs6/V7X8MlltfTvk8bskgLKpgUYPkBdg0hXXDEQvBCYTSgIzoeAAd8GvmVm\nTV34/pnAWu/1dmAGoVXYRC5qcHYGf3PzVXzyxlH8cetBKtYE+enrO1j8hzquG9mfstIAt4wbRHpK\nxB+LEelxLhkIzrnP8/4QqCTUCfyO0HMJyzsaBs65YjOrdM497u06TOgJaAjdtdS/Y+VLokpOctx4\n9UBuvHog+5tP82x1PcvX1vPpinXk9klj9tTQWENRXl+/SxWJG5frEBYR6gQWmNlP27/hXKfnosm9\nYHsVodABGEmoSxDpkEFZGXzqpqv4xEdG8ca2Q1RUBfnPN3aw5I91fKAol7LSALeOG0xGqroGkcu5\nXCCsA6YAi71r/SvaP5TWUee7g/b7zKzOObfCOVdM6DbWvxg/cM6VA+UAgUCgs18vCSApyXH96Dyu\nH53HgWOnWVXTwPKqej6zfD39eqdyf3EBD5YGGDVQXYPIxVz2LiPnXDah3+DnEHr+4CihS0ezgWIz\n2xD2F4XmPIJQl7CA0ENuEJopdYlzbrGZLbj40d4HdZeRdFBbm/Gn7YepqArym037aGkzSofnUja9\nkI+Oz1fXIAkhEk8qjwAeIPTbehGhy0nP0sHOwfuN/3FCM6fWtguKOjOrvdyxCgTpioPHzrC6toHl\nVUF2Hj5Jdq9UZhUPZV5pgKsGZfpdnkjERPQ5BC8cHgPuJxQObWbWoVtYO0OBIN2hrc34c91hlnld\nw7lWo2RYP8pKA9wxUV2D9DxRe1LZu/5fbmaPdelEYVAgSHc7fDzUNVRU1bPj0AmyMlKYVVxAWWmA\nqwera5CeIapTV0SLAkEixcz4c90RKqqC/HrjPs62tlEcyKGsNMCdE4fQK01dg8QvBYJIJx05cZbn\nahuoqAqy/eAJMjNSuG/KUB6cFmDsEC0hLvFHgSDSRWbG2p1HqagK8vJbeznb0sbkwhzmlQa4c1I+\nvdMiPmwm0i0UCCLdqPHkWZ6r3U1FVZCtB47TNz2FeyYPoaw0wPih2X6XJ3JZCgSRCDAzanYdZVlV\nkJff3MuZljYmFmRTVhrgrklD6JuurkFijwJBJMKaTp7j+XWhO5Te2X+MPmnJ3D059FzDhAJ1DRI7\nFAgiUWJm1AYbqagK8os393D6XBvjh2ZRVhrg7klDyMxI9btESXAKBBEfNJ06x4vrd7NsTZC39x2j\nd1oyd08KjTVMLMjuysSQIp2mQBDxkZmxoaGJijVBXtqwh1PnWhmbn0XZ9AD3TB5ClroGiSIFgkiM\nOHb6HC+u38OyNUE2722mV2oyd03Kp6w0wOTCHHUNEnEKBJEYY2a8tbuJiqogL67fw8mzrYwZnElZ\naYB7pwwlu5e6BokMBYJIDDt+poWX1u+hoirIW7ubyEhN4o4JQ5g3vZDiQD91DdKtFAgiceKthiYq\n1gZ5cd1uTpxtZfSgvpSVBpg1pYDs3uoapOsUCCJx5sSZFn6+IdQ1bGhoIj0liTsm5FM2PUDJMHUN\n0nkKBJE4tnF3E8vXBnlh3R6On2lh1MDzXcNQ+vVJ87s8iTMKBJEe4OTZFn7x5l4qqoKsCzaSlpLE\n7eMHU1YaoHRErroGCYsCQaSH2bK3meVVQZ5bt5tjp1soyuvDvNIAs4oLyFXXIJehQBDpoU6dbeXl\nt0JdQ82uo6QlJ3Hr+MGUlRZybVF/dQ3yF2I6EJxzC81skfd6NtAIFJnZkssdp0AQeb939h2joirI\nc7UNNJ9uYcSAPjw4rZD7pxYwoG+63+VJjIjZQHDOzQAeN7OZ3nrMmFmtt/+ImdVe6lgFgsjFnT7X\nyi+9rmHtzqOkJjtuGTeYeaUBri3qT1KSuoZEFm4gxMLk7U8CMwl1CJV+FyMSjzJSk5lVXMCs4gK2\n7j9GRVU9q2sbePnNvQzr35sHpwWYPbWAvEx1DXJpUe0QnHPFXjfwipnN9PYtBuYA881s1eWOV4cg\nEr7T51r59cZ9LKsKUrXjCClJjlvGDaKsNMAHRw5Q15BAYrVDyG2/4ZzLITR+8C1gqXOu1szqolyT\nSI+UkZrMvVOGcu+UoWw7cJwVa4Osqmngl2/tozC3Fw9OC/BASQEDMzP8LlViRNQ6hPPdgff6FW8M\nYSGwxMwavcHlovODzRejDkGka860tPKbTfupWBPkv+sOk5LkmHHNIMqmB/jwKHUNPVUsdghFzrki\nQl1C7vkB5fPMbJVzrvzCg7x95QCBQCAqhYr0VOkpoQV77p40hLqDx1mxtp5naxr49aZ9DM3pxYPT\nCpkzrZBBWeoaEpEfdxmVA48DD3jjCQuBOiBXt52KRN+ZllZe2byfiqog/7XtMMlJjpvGDGReaYDr\nR+eRrK4h7sXsbaddoUAQiaydh06wfG09q2rqOXT8LEOyM5g7LcCcaQXkZ/fyuzzpJAWCiHTa2ZY2\nKreEuobXtx4iycFNYwZSVhrghtF5pCQn+V2idEAsjiGISJxIS0ni9gn53D4hn+DhkyxfG2RldQOV\nW6rJz85gTklorGFojrqGnkQdgoiE5VxrG7/bsp+Kqnr+uPUgDvjI1aGu4car1TXEMl0yEpGIqT9y\nkpXV9axYW8+BY2cYlJXOXK9rKOjX2+/y5AIKBBGJuJbWNl59+wAVVUF+/+5BAG4YnceD0wLcfM1A\nUtU1xAQFgohEVcPRk6ysbmDl2nr2NZ8mLzOdOSUFPDgtQGGuugY/KRBExBctrW38/p2DVFQFee2d\nAxjwoVEDmFcaYMbYQeoafKBAEBHf7Wk8xcrqelaurWdP02kG9E3ngZICHpxWyLD+ffwuL2EoEEQk\nZrS2GX949wDL1tTz6tv7abNQ11BWGmDm2EGkpahriCQFgojEpH1Np9+7Q2l34yn690ljtjfWMGKA\nuoZIUCCISExrbTNe3xoaa6jccoDWNuPaov7Mmx7glnGDSE9J9rvEHkOBICJx40DzaZ6taaCiKkjD\n0VPk9klj9tTQWENRXl+/y4t7CgQRiTttbcYb2w5RURXklc37aWkzpo/IZd70ALeOG0xGqrqGzlAg\niEhcO3DsNKtqGlheVU/wyElyeqdyf3EBZaWFjBqY6Xd5cUWBICI9Qlub8afth6moCvLbzfs412qU\nDs+lbHohHx2fr64hDAoEEelxDh0/43UNQXYePkl2r1RmFQ+lrDTA6EHqGi5FgSAiPVZbm/HnusMs\nqwrym02hrqFkWD/KSgPcPiGfXmnqGtpTIIhIQjh8/AzP1e6moipI3aETZGakMGvKUMqmBxgzOMvv\n8mKCAkFEEoqZsWbHESqqgvzqrX2cbW1jSiCHstIAd07Mp3da4q4HpkAQkYR15MRZnqsNPdew/eAJ\nMtNTuHdKaKxh7JDE6xpiOhCccwvNbJFzrhioAeq8tyrNbMGljlMgiEhHmBlrdx6loirIy2/t5WxL\nG5MKc5hXWsidE4fQJz0xuoaYDQTn3AzgcTOb6ZybYWaV3v5ioNHM6i51rAJBRDqr8eTZ98Yath44\nTt/0FO6ZPISy0gDjh2b7XV5EhRsIvsbj+TDwlJjZEt+KEZEeLad3Gn/1oRH87w8OpzZ4lGVr6llV\n08Aza4JMLMimrDTAXZOG0DdBuoaLiWqH4JwrNrNa59wrZjaz3f4ZQLWZNV7ueHUIItKdmk6e44X1\nu1m2Jsg7+4/RJy2ZuycPZV5pgAkFPadriNUOIfcS+2de0C2IiERcdu9UPnbdcB69dhjr6hupWBPk\n+XWhwehxQ7IoKw1wz+QhZGak+l1qVEStQzjfHXivL+wQ3rd9wXHlQDlAIBCYumvXrqjUKyKJqenU\nOV5av5tn1gR5e98xeqUmc/ekIZRNDzCpIBvnnN8ldljMDSo752Z7L3OBBcB87/JREbD4UoHQni4Z\niUi0mBkbGpqoWBPkpQ17OHUu57n7AAAEl0lEQVSulWvys5hXWsg9U4aSFUddQ8xdMjKzVfDeb/w5\nF7x9yTuLRET84JxjcmEOkwtz+Ls7r+HF9XtYtibIV1/cxDd/+TZ3TsynbHqAKYU5cdk1XIweTBMR\nCZOZ8dbuJiqqgry4fg8nz7YyZnAmZaUB7p0ylOxesdk1xNwlo+6gQBCRWHH8TAs/37CHiqogbzY0\nkZGaxB0ThjBveiHFgX4x1TUoEEREomRju67h+JkWRg/qS1lpgPumDCWnd5rf5SkQRESi7cSZFn7x\n5h6WVdWzob6RtJQk7piQT1lpgGnD/esaFAgiIj7atKeJ5VX1vLBuN8fOtDAyrw9lpQHuLy6gX5/o\ndg0KBBGRGHDybAu/eHMvFVVB1gUbSUtO4qMTBlNWGmD6iNyodA0KBBGRGLNlbzPLq4I8t243x063\nUDTA6xqmFpAbwa5BgSAiEqNOnW3l5bdCXUPNrqOkJSdx6/jBlJUWcm1R/27vGhQIIiJx4N39x6io\nCrK6poHm0y2MGNCHB6cVcv/UAgb0Te+W71AgiIjEkdPnWvnVxr1UrKmnaucRUpMdt4wbzLzSANcW\n9ScpqfNdgwJBRCRObTtwjIqqelbXNtB48hyB3N58d+4kpg671ITRlxdzcxmJiEh4Rg3M5Kt3juUL\nt17NbzbtY3lVPQX9ekf8exUIIiIxKiM1mXsmD+WeyUOj8n1JUfkWERGJeQoEEREBFAgiIuJRIIiI\nCKBAEBERjwJBREQABYKIiHgUCCIiAsTZ1BXOuYPArk4eng00dWM50Th/d5yzq+fo7PEDgENd+F4J\nX6T/2/ZLrP69/Kirq985zMzyrvShuAqErnDOLTGz8ng6f3ecs6vn6OzxzrnqcOZOka6L9H/bfonV\nv5cfdUXrOxPpktHP4/D83XHOrp4j0v+7Sdf11P+PYvXv5UddUfnOhOkQJLrUIYjEH01uJ5Gy5GI7\nnXNFQA4wA1hlZnVRrUpELimRLhlJN3LOFV+wPds5N8M5txDAzC4aCEAxUAdUArMjW6WIdIQCQTrM\nOTcDeLbddjGAmVUCjReGRXtmtsrMGvE6hEjXKiLh0yUj6TAzq3TOtb/UMxd4xXtdR+gf+1rn3IUd\nQKWZNXqBUqnLRSKxRYEg3SEHONJuuz+EuoELP+iFweNAnXPulYt9RkT8oUCQqPIuK1X6XYeI/CWN\nIUh3aATOr/6dAxz2sRYR6SQFgnSHFUCR97oIdQAicUmBIB3mDRaXnB80NrNab/8MoPH8tojEFz2p\nLCIigDoEERHxKBBERARQIIiIiEeBICIigAJBREQ8CgQREQEUCCIi4lEgiIgIoEAQERGPAkFERAAF\ngoiIeBQIIl3grSW93fs52u71s1c+WiS2aIEckU5yzhUBmNlIb7vczJb4W5VI52m2U5FOcs7lmFmj\n93o2oam/tRaExC1dMhLppPNh4JmrMJB4p0AQ6R5FV/6ISGxTIIh0kXOuGKjzuw6RrlIgiHTdDOAV\nv4sQ6SoNKouICKAOQUREPAoEEREBFAgiIuJRIIiICKBAEBERjwJBREQABYKIiHgUCCIiAigQRETE\n8/8BFuw2uy7XM4UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10599b940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "line1, = ax.plot(taurange, ac_range2)\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel(r'Accuracy', fontsize=16)\n",
    "ax.set_xlabel(r'$\\tau$', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hackathon]",
   "language": "python",
   "name": "conda-env-hackathon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
