{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from numba import njit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from numpy import linalg as LA\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kernel import *\n",
    "from utils import preprocessing\n",
    "from kernel_functions import * \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x, z):\n",
    "    K = np.dot(x, z.T)\n",
    "    return K\n",
    "\n",
    "def gaussian_kernel(x, z, gamma):\n",
    "    s1 = x.shape[0]\n",
    "    s2 = z.shape[0]\n",
    "    xx = np.repeat((LA.norm(x, axis=1)**2).reshape((-1, 1)), s2, axis=1)\n",
    "    zz = np.repeat((LA.norm(z, axis=1)**2).reshape((-1, 1)), s1, axis=1)\n",
    "    # K_tmp = np.exp(2 * linear_kernel(x, z) + xx + zz.T / (gamma**2))\n",
    "    K_tmp = np.exp((2 * linear_kernel(x, z) + xx + zz.T) / (gamma**2))\n",
    "    # K = np.array([np.exp(LA.norm(x - z1, axis=1)**2/(gamma**2)) for z1 in z])\n",
    "    return K_tmp\n",
    "\n",
    "def fit(K, y, lamb = 0.1): \n",
    "    y = (y - 0.5) * 2\n",
    "    # We solve the Dual\n",
    "    NUM = K.shape[0]\n",
    "    P = matrix(2 * K * y.reshape((-1,1)).dot(y.reshape((1,-1))))\n",
    "    q = matrix(-np.ones((NUM, 1)))\n",
    "    G = matrix(np.concatenate((-np.eye(NUM), np.eye(NUM)), axis=0))\n",
    "    h = matrix(np.concatenate((np.zeros(NUM), lamb* np.ones(NUM)),axis=0))\n",
    "    A = matrix(y.reshape(1, -1))\n",
    "    b = matrix(np.zeros(1))\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol = solvers.qp(P, q, G, h, A, b)\n",
    "    alphas = np.array(sol['x']) * y[:, None]\n",
    "    bias = np.mean(y - np.dot(K, alphas))\n",
    "    return alphas, bias\n",
    "\n",
    "\n",
    "def predict(alphas, bias, K_test):\n",
    "    mat = np.dot(K_test, alphas)\n",
    "    mat = mat + bias>0.\n",
    "    return mat.reshape(-1)\n",
    "\n",
    "def testing_lambda(X_train, Y_train, X_test, Y_test, lamb=0.1, kernel='linear', gamma=1000, Kernels=None):\n",
    "    if kernel=='linear':\n",
    "        K = linear_kernel(X_train, X_train)\n",
    "        K_test = linear_kernel(X_test, X_train)\n",
    "    if kernel=='gaussian':\n",
    "        K = gaussian_kernel(X_train, X_train, gamma)\n",
    "        K_test = gaussian_kernel(X_test, X_train, gamma)\n",
    "    if kernel=='custom':\n",
    "        K = Kernels[0]\n",
    "        K_test = Kernels[1]\n",
    "        \n",
    "    alphas, bias = fit(K, Y_train, lamb=lamb)\n",
    "    \n",
    "    Y_pred = predict(alphas, bias, K_test)\n",
    "    #Y_test = (Y_test - 0.5) * 2\n",
    "    acc_test = np.sum(Y_pred == Y_test)/Y_test.shape[0]\n",
    "    \n",
    "    Y_pred_train = predict(alphas, bias, K)\n",
    "    acc_train = np.sum(Y_pred_train == Y_train)/X_train.shape[0]\n",
    "    \n",
    "    if np.alltrue(Y_pred==1):\n",
    "        print(\"test Toute les valeurs sont TRUE\")\n",
    "    \n",
    "    if np.alltrue(Y_pred==-1):\n",
    "        print(\"Toute les valeurs sont FALSE\")\n",
    "    \n",
    "    \n",
    "    return acc_train, acc_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_tmp = linear_kernel(X_train, X_train)\n",
    "#gaussian_kernel(X_test, X_train, gamma=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.repeat((LA.norm(X_train, axis=1)**2).reshape((-1, 1)), 30, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:25<00:00, 79.79it/s]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.45it/s]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# load all data as the numpy array type\n",
    "#X = pd.read_csv('data/Xtr1_mat50.csv', sep=' ', header=None).values\n",
    "X_raw0 = pd.read_csv('data/Xtr0.csv', sep= ' ', header = None).values.reshape((-1))\n",
    "X_raw1 = pd.read_csv('data/Xtr1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_raw2 = pd.read_csv('data/Xtr2.csv', sep=' ', header=None).values.reshape((-1))\n",
    "\n",
    "# transform k-fold\n",
    "FOLD = 32\n",
    "X_0 = to_k_fold(X_raw0, fold=FOLD)\n",
    "X_1 = to_k_fold(X_raw1, fold=FOLD)\n",
    "X_2 = to_k_fold(X_raw2, fold=FOLD)\n",
    "\n",
    "# transform to an array of string\n",
    "X_valid0 = pd.read_csv('data/Xte0.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_valid1 = pd.read_csv('data/Xte1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_valid2 = pd.read_csv('data/Xte1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "\n",
    "\n",
    "Y0 = pd.read_csv('data/Ytr0.csv', sep=',', header=0)['Bound'].values\n",
    "Y1 = pd.read_csv('data/Ytr1.csv', sep=',', header=0)['Bound'].values\n",
    "Y2 = pd.read_csv('data/Ytr2.csv', sep=',', header=0)['Bound'].values\n",
    "\n",
    "#print('numerical features shape', X.shape)\n",
    "#print('numerical features first row', X[0])\n",
    "# print('sequences shape: ', X_raw0.shape)\n",
    "# print('sequence first row: ', X_raw0[0])\n",
    "# print('labels shape', Y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel constructed\n",
      "lamb = 1e-05, acc train = 0.8608333333333333, acc_test = 0.71625\n",
      "lamb = 2e-05, acc train = 0.8866666666666667, acc_test = 0.72\n",
      "lamb = 3.0000000000000004e-05, acc train = 0.9083333333333333, acc_test = 0.71\n",
      "lamb = 4e-05, acc train = 0.9166666666666666, acc_test = 0.7025\n",
      "lamb = 5e-05, acc train = 0.925, acc_test = 0.6975\n",
      "lamb = 6e-05, acc train = 0.9291666666666667, acc_test = 0.6975\n",
      "lamb = 7.000000000000001e-05, acc train = 0.9325, acc_test = 0.6975\n",
      "lamb = 8e-05, acc train = 0.9375, acc_test = 0.6925\n",
      "lamb = 9e-05, acc train = 0.9391666666666667, acc_test = 0.69125\n"
     ]
    }
   ],
   "source": [
    "# bias_term = 1e6\n",
    "gamma = 1000\n",
    "X_train, Y_train, X_test, Y_test = preprocessing(X_0, Y0, percent=0.6)\n",
    "# K = gaussian_kernel(X_train, X_train, gamma)\n",
    "# K_test = gaussian_kernel(X_test, X_train, gamma)\n",
    "print(\"kernel constructed\")\n",
    "\n",
    "for lamb in np.arange(1e-5, 1e-4, 1e-5):\n",
    "    acc_train, acc_test = testing_lambda(X_train, Y_train, X_test, Y_test, \n",
    "                                         lamb=lamb, gamma = 1000,\n",
    "                                         kernel='linear'#, Kernels = (K, K_test) \n",
    "                                        )\n",
    "    print(\"lamb = {}, acc train = {}, acc_test = {}\".format(lamb, acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 1e-05, acc train = 0.90625, acc_test = 0.8525\n",
      "lamb = 2e-05, acc train = 0.931875, acc_test = 0.8675\n",
      "lamb = 3.0000000000000004e-05, acc train = 0.94375, acc_test = 0.8825\n",
      "lamb = 4e-05, acc train = 0.9475, acc_test = 0.8775\n",
      "lamb = 5e-05, acc train = 0.955, acc_test = 0.8725\n",
      "lamb = 6e-05, acc train = 0.958125, acc_test = 0.875\n",
      "lamb = 7.000000000000001e-05, acc train = 0.960625, acc_test = 0.865\n",
      "lamb = 8e-05, acc train = 0.96375, acc_test = 0.8625\n",
      "lamb = 9e-05, acc train = 0.965625, acc_test = 0.8625\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = preprocessing(X_1, Y1, percent=0.8)\n",
    "for lamb in np.arange(1e-5, 1e-4, 1e-5):\n",
    "    acc_train, acc_test = testing_lambda(X_train, Y_train, X_test, Y_test, lamb=lamb)\n",
    "    print(\"lamb = {}, acc train = {}, acc_test = {}\".format(lamb, acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 7e-06, acc train = 0.781875, acc_test = 0.63\n",
      "lamb = 8e-06, acc train = 0.7825, acc_test = 0.6275\n",
      "lamb = 8.999999999999999e-06, acc train = 0.7875, acc_test = 0.63\n",
      "lamb = 9.999999999999999e-06, acc train = 0.79125, acc_test = 0.635\n",
      "lamb = 1.1e-05, acc train = 0.79625, acc_test = 0.6275\n",
      "lamb = 1.1999999999999999e-05, acc train = 0.800625, acc_test = 0.6275\n",
      "lamb = 1.2999999999999998e-05, acc train = 0.801875, acc_test = 0.63\n",
      "lamb = 1.3999999999999998e-05, acc train = 0.80375, acc_test = 0.6275\n",
      "lamb = 1.4999999999999999e-05, acc train = 0.809375, acc_test = 0.625\n",
      "lamb = 1.6e-05, acc train = 0.810625, acc_test = 0.625\n",
      "lamb = 1.6999999999999996e-05, acc train = 0.814375, acc_test = 0.635\n",
      "lamb = 1.7999999999999997e-05, acc train = 0.81875, acc_test = 0.635\n",
      "lamb = 1.8999999999999998e-05, acc train = 0.819375, acc_test = 0.63\n",
      "lamb = 1.9999999999999998e-05, acc train = 0.82125, acc_test = 0.6225\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = preprocessing(X_2, Y2, percent=0.8)\n",
    "for lamb in np.arange(7e-6, 2e-5, 1e-6):\n",
    "    acc_train, acc_test = testing_lambda(X_train, Y_train, X_test, Y_test, lamb=lamb)\n",
    "    print(\"lamb = {}, acc train = {}, acc_test = {}\".format(lamb, acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_train, Y_train, X_test, lamb=1.):\n",
    "    # X_train, Y_train, X_test, Y_test = preprocessing(X, Y, percent=0.8)\n",
    "    X_train_preprocess = np.concatenate((X_train, np.ones((X_train.shape[0], 1))), axis=1)\n",
    "    X_test_preprocess = np.concatenate((X_test, np.ones((X_test.shape[0], 1))), axis=1)\n",
    "    K = X_train_preprocess.dot(X_train_preprocess.T)\n",
    "    K_test = X_test_preprocess.dot(X_train_preprocess.T)\n",
    "    w = solve_svm(K, Y_train, lamb=lamb, kktreg = 1e-9)\n",
    "    n = K.shape[0]\n",
    "    Y_predicted = np.dot(K_test, w[:n]) > 0.\n",
    "    Y_predicted = Y_predicted + 0.0\n",
    "    # result = ((Y_test+1.)/ 2. == np.transpose(Y_predicted))\n",
    "    Y_predicted_train = np.dot(K, w[:n]) > 0.\n",
    "    result_train = ((Y_train+1)/ 2 == np.transpose(Y_predicted_train))\n",
    "    if np.alltrue(Y_predicted):\n",
    "        print(\"Toute les valeurs sont TRUE\")\n",
    "    if np.alltrue(Y_predicted==False):\n",
    "        print(\"Toute les valeurs sont FALSE\")\n",
    "    print(\"lambda = {}\".format(lamb))\n",
    "    print(\"train : {}\".format(np.mean(result_train)))\n",
    "    return Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.52it/s]\n",
      "100%|██████████| 1000/1000 [00:31<00:00, 32.20it/s]\n",
      "100%|██████████| 1000/1000 [00:31<00:00, 31.45it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test0 = to_k_fold(X_valid0, fold=32)\n",
    "X_test1 = to_k_fold(X_valid1, fold=32)\n",
    "X_test2 = to_k_fold(X_valid2, fold=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  9.2621e+00  1.2864e+01  5e+03  2e+00  3e+06\n",
      " 1:  7.2937e+00 -2.8847e+02  3e+02  1e-01  2e+05\n",
      " 2:  2.5566e+00 -5.0199e+01  5e+01  2e-02  3e+04\n",
      " 3:  1.6728e+00 -5.7320e+00  7e+00  2e-03  3e+03\n",
      " 4:  1.3318e+00  8.2074e-02  1e+00  2e-04  3e+02\n",
      " 5:  6.3867e-01  5.2630e-01  1e-01  4e-06  8e+00\n",
      " 6:  5.9189e-01  5.6471e-01  3e-02  9e-07  2e+00\n",
      " 7:  5.8054e-01  5.7490e-01  6e-03  1e-07  2e-01\n",
      " 8:  5.7782e-01  5.7717e-01  7e-04  9e-09  2e-02\n",
      " 9:  5.7752e-01  5.7743e-01  9e-05  1e-09  2e-03\n",
      "10:  5.7747e-01  5.7747e-01  4e-06  7e-10  7e-05\n",
      "11:  5.7747e-01  5.7747e-01  8e-08  7e-10  1e-06\n",
      "12:  5.7747e-01  5.7747e-01  2e-09  7e-10  2e-08\n",
      "Optimal solution found.\n",
      "lambda = 1.5\n",
      "train : 0.833\n"
     ]
    }
   ],
   "source": [
    "Y0_t = (Y0 - 0.5) *2\n",
    "w, bias = fit(X_0, Y0_t, lamb=1.)\n",
    "Y_pred0 = predict(w, bias, X_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  6.9083e+00  1.0034e+01  5e+03  2e+00  2e+07\n",
      " 1:  5.5102e+00 -2.2544e+02  2e+02  8e-02  1e+06\n",
      " 2:  1.8893e+00 -2.8892e+01  3e+01  9e-03  1e+05\n",
      " 3:  1.4867e+00 -3.5336e+00  5e+00  1e-03  2e+04\n",
      " 4:  1.1001e+00 -8.0780e-02  1e+00  2e-04  2e+03\n",
      " 5:  4.9247e-01  3.3941e-01  2e-01  1e-05  2e+02\n",
      " 6:  4.2388e-01  3.8429e-01  4e-02  3e-06  4e+01\n",
      " 7:  4.0657e-01  3.9766e-01  9e-03  5e-07  7e+00\n",
      " 8:  4.0255e-01  4.0082e-01  2e-03  8e-08  1e+00\n",
      " 9:  4.0166e-01  4.0152e-01  1e-04  5e-09  8e-02\n",
      "10:  4.0159e-01  4.0158e-01  7e-06  7e-10  3e-03\n",
      "11:  4.0159e-01  4.0159e-01  3e-07  8e-10  1e-04\n",
      "12:  4.0159e-01  4.0159e-01  8e-09  8e-10  2e-06\n",
      "13:  4.0159e-01  4.0159e-01  3e-10  8e-10  2e-08\n",
      "Optimal solution found.\n",
      "lambda = 2.0\n",
      "train : 0.9205\n"
     ]
    }
   ],
   "source": [
    "Y1_t = (Y1 - 0.5) *2\n",
    "w, bias = fit(X_1, Y1_t, lamb=1.)\n",
    "Y_pred1 = predict(w, bias, X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.5420e+01  2.1448e+01  5e+03  2e+00  6e+06\n",
      " 1:  1.0812e+01 -3.7609e+02  4e+02  1e-01  5e+05\n",
      " 2:  2.9521e+00 -5.2604e+01  6e+01  2e-02  6e+04\n",
      " 3:  1.8370e+00 -6.9842e+00  9e+00  2e-03  8e+03\n",
      " 4:  1.5149e+00  1.9806e-01  1e+00  1e-04  5e+02\n",
      " 5:  8.2708e-01  6.2501e-01  2e-01  2e-05  7e+01\n",
      " 6:  7.2171e-01  6.8425e-01  4e-02  3e-06  1e+01\n",
      " 7:  7.0418e-01  6.9742e-01  7e-03  3e-07  1e+00\n",
      " 8:  7.0081e-01  7.0005e-01  8e-04  3e-08  1e-01\n",
      " 9:  7.0044e-01  7.0035e-01  9e-05  3e-09  1e-02\n",
      "10:  7.0039e-01  7.0039e-01  6e-06  7e-10  7e-04\n",
      "11:  7.0039e-01  7.0039e-01  2e-07  8e-10  2e-05\n",
      "12:  7.0039e-01  7.0039e-01  5e-09  8e-10  3e-07\n",
      "13:  7.0039e-01  7.0039e-01  2e-10  8e-10  3e-09\n",
      "Optimal solution found.\n",
      "lambda = 1.8\n",
      "train : 0.769\n"
     ]
    }
   ],
   "source": [
    "Y2_t = (Y2 - 0.5) *2\n",
    "w, bias = fit(X_2, Y2_t, lamb=1.)\n",
    "Y_pred2 = predict(w, bias, X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0 = np.transpose(Y_pred0)[:][0]\n",
    "test1 = np.transpose(Y_pred1)[:][0]\n",
    "test2 = np.transpose(Y_pred2)[:][0]\n",
    "\n",
    "bound = np.concatenate((test0,test1,test2), axis=0).reshape((-1)).astype(int)\n",
    "final = pd.DataFrame(np.arange(3000), columns=['Id'])\n",
    "final['Bound'] = bound\n",
    "final.to_csv('resultk_fold.csv', index= None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
