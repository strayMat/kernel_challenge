{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from numba import njit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from numpy import linalg as LA\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kernel import *\n",
    "\n",
    "from kernel_functions import * \n",
    "from preprocessing import preprocessing\n",
    "from collections import defaultdict\n",
    "\n",
    "from scipy.linalg import eigh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x, z):\n",
    "    K = np.dot(x, z.T)\n",
    "    return K\n",
    "\n",
    "def gaussian_kernel(x, z, gamma):\n",
    "   \n",
    "    # s1 = x.shape[0]\n",
    "    # s2 = z.shape[0]\n",
    "    # xx = np.repeat((LA.norm(x, axis=1)**2).reshape((-1, 1)), s2, axis=1)\n",
    "    # zz = np.repeat((LA.norm(z, axis=1)**2).reshape((-1, 1)), s1, axis=1)\n",
    "    # K_tmp = np.exp(2 * linear_kernel(x, z) + xx + zz.T / (gamma**2))\n",
    "    # K_tmp = np.exp((2 * linear_kernel(x, z) + xx + zz.T) / (gamma**2))\n",
    "    # K = np.array([np.exp(LA.norm(x - z1, axis=1)**2/(gamma**2)) for z1 in z])\n",
    "    D = l2distance(x, z)\n",
    "    K_tmp = np.array(np.exp(D**2/(gamma**2)))\n",
    "    return K_tmp\n",
    "\n",
    "def fit(K, y, lamb = 0.1): \n",
    "    y = (y - 0.5) * 2\n",
    "    # We solve the Dual\n",
    "    NUM = K.shape[0]\n",
    "    P = matrix(2 * K * y.reshape((-1,1)).dot(y.reshape((1,-1))))\n",
    "    q = matrix(-np.ones((NUM, 1)))\n",
    "    G = matrix(np.concatenate((-np.eye(NUM), np.eye(NUM)), axis=0))\n",
    "    h = matrix(np.concatenate((np.zeros(NUM), lamb* np.ones(NUM)),axis=0))\n",
    "    A = matrix(y.reshape(1, -1))\n",
    "    b = matrix(np.zeros(1))\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol = solvers.qp(P, q, G, h, A, b)\n",
    "    alphas = np.array(sol['x']) * y[:, None]\n",
    "    bias = np.mean(y - np.dot(K, alphas))\n",
    "    return alphas, bias\n",
    "\n",
    "\n",
    "def predict(alphas, bias, K_test):\n",
    "    mat = np.dot(K_test, alphas)\n",
    "    mat = mat + bias>0.\n",
    "    return mat.reshape(-1)\n",
    "\n",
    "def testing_lambda(X_train, Y_train, X_test, Y_test, lamb=0.1, kernel='linear', gamma=1000, Kernels=None):\n",
    "    if kernel=='linear':\n",
    "        K = linear_kernel(X_train, X_train)\n",
    "        K_test = linear_kernel(X_test, X_train)\n",
    "    if kernel=='gaussian':\n",
    "        K = gaussian_kernel(X_train, X_train, gamma)\n",
    "        K_test = gaussian_kernel(X_test, X_train, gamma)\n",
    "    if kernel=='custom':\n",
    "        K = Kernels[0]\n",
    "        K_test = Kernels[1]\n",
    "        \n",
    "    alphas, bias = fit(K, Y_train, lamb=lamb)\n",
    "    \n",
    "    Y_pred = predict(alphas, bias, K_test)\n",
    "    #Y_test = (Y_test - 0.5) * 2\n",
    "    acc_test = np.sum(Y_pred == Y_test)/Y_test.shape[0]\n",
    "    \n",
    "    Y_pred_train = predict(alphas, bias, K)\n",
    "    acc_train = np.sum(Y_pred_train == Y_train)/X_train.shape[0]\n",
    "    \n",
    "    if np.alltrue(Y_pred==1):\n",
    "        print(\"test Toute les valeurs sont TRUE\")\n",
    "    \n",
    "    if np.alltrue(Y_pred==-1):\n",
    "        print(\"Toute les valeurs sont FALSE\")\n",
    "    \n",
    "    \n",
    "    return acc_train, acc_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:21<00:00, 91.61it/s]\n",
      "100%|██████████| 2000/2000 [00:23<00:00, 85.16it/s]\n",
      "100%|██████████| 2000/2000 [00:19<00:00, 100.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# load all data as the numpy array type\n",
    "#X = pd.read_csv('data/Xtr1_mat50.csv', sep=' ', header=None).values\n",
    "X_raw0 = pd.read_csv('data/Xtr0.csv', sep= ' ', header = None).values.reshape((-1))\n",
    "X_raw1 = pd.read_csv('data/Xtr1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_raw2 = pd.read_csv('data/Xtr2.csv', sep=' ', header=None).values.reshape((-1))\n",
    "\n",
    "# transform k-fold\n",
    "X_0 = to_k_fold(X_raw0, fold1=9, fold2 = 32)\n",
    "X_1 = to_k_fold(X_raw1, fold1=9, fold2 = 32)\n",
    "X_2 = to_k_fold(X_raw2, fold1=9, fold2 = 32)\n",
    "\n",
    "# transform to an array of string\n",
    "X_valid0 = pd.read_csv('data/Xte0.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_valid1 = pd.read_csv('data/Xte1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_valid2 = pd.read_csv('data/Xte1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "\n",
    "\n",
    "Y0 = pd.read_csv('data/Ytr0.csv', sep=',', header=0)['Bound'].values\n",
    "Y1 = pd.read_csv('data/Ytr1.csv', sep=',', header=0)['Bound'].values\n",
    "Y2 = pd.read_csv('data/Ytr2.csv', sep=',', header=0)['Bound'].values\n",
    "\n",
    "#print('numerical features shape', X.shape)\n",
    "#print('numerical features first row', X[0])\n",
    "# print('sequences shape: ', X_raw0.shape)\n",
    "# print('sequence first row: ', X_raw0[0])\n",
    "# print('labels shape', Y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(X_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:06<00:00, 29.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_0_t = to_k_fold(X_raw0[:], fold1=5, fold2 = 62)\n",
    "print(X_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 1e-05, acc train = 0.84, acc_test = 0.7375\n",
      "lamb = 2e-05, acc train = 0.865625, acc_test = 0.72\n",
      "lamb = 3e-05, acc train = 0.880625, acc_test = 0.715\n"
     ]
    }
   ],
   "source": [
    "# bias_term = 1e6\n",
    "gamma = 1000\n",
    "X_train, Y_train, X_test, Y_test = preprocessing(X_0, Y0, percent=0.8, seed=2)\n",
    "# K = gaussian_kernel(X_train, X_train, gamma)\n",
    "# K_test = gaussian_kernel(X_test, X_train, gamma)\n",
    "# print(\"kernel constructed\")\n",
    "\n",
    "for lamb in [1e-5, 2e-5, 3e-5]:\n",
    "    acc_train, acc_test = testing_lambda(X_train, Y_train, X_test, Y_test, \n",
    "                                         lamb=lamb, gamma = 1000,\n",
    "                                         kernel='linear'#, Kernels = (K, K_test) \n",
    "                                        )\n",
    "    print(\"lamb = {}, acc train = {}, acc_test = {}\".format(lamb, acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 1e-06, acc train = 0.754375, acc_test = 0.745\n",
      "lamb = 2e-06, acc train = 0.765, acc_test = 0.7475\n",
      "lamb = 3e-06, acc train = 0.78875, acc_test = 0.7725\n",
      "lamb = 4e-06, acc train = 0.80625, acc_test = 0.785\n",
      "lamb = 4.9999999999999996e-06, acc train = 0.836875, acc_test = 0.795\n",
      "lamb = 5.999999999999999e-06, acc train = 0.851875, acc_test = 0.7925\n",
      "lamb = 7e-06, acc train = 0.863125, acc_test = 0.7975\n",
      "lamb = 8e-06, acc train = 0.8725, acc_test = 0.8075\n",
      "lamb = 9e-06, acc train = 0.884375, acc_test = 0.8075\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = preprocessing(X_1, Y1, percent=0.8)\n",
    "for lamb in np.arange(1e-6, 1e-5, 1e-6):\n",
    "    acc_train, acc_test = testing_lambda(X_train, Y_train, X_test, Y_test, lamb=lamb)\n",
    "    print(\"lamb = {}, acc train = {}, acc_test = {}\".format(lamb, acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y0)/Y0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 0.0001, acc train = 0.8872222222222222, acc_test = 0.495\n",
      "lamb = 0.001, acc train = 0.9861111111111112, acc_test = 0.625\n",
      "lamb = 0.01, acc train = 1.0, acc_test = 0.605\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = preprocessing(X_tmp2, Y2, percent=0.9)\n",
    "for lamb in [1e-4, 1e-3, 1e-2]:\n",
    "    acc_train, acc_test = testing_lambda(X_train, Y_train, X_test, Y_test, lamb=lamb)\n",
    "    print(\"lamb = {}, acc train = {}, acc_test = {}\".format(lamb, acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y2)/Y2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_train, Y_train, X_test, lamb=1.):\n",
    "    # X_train, Y_train, X_test, Y_test = preprocessing(X, Y, percent=0.8)\n",
    "    X_train_preprocess = np.concatenate((X_train, np.ones((X_train.shape[0], 1))), axis=1)\n",
    "    X_test_preprocess = np.concatenate((X_test, np.ones((X_test.shape[0], 1))), axis=1)\n",
    "    K = X_train_preprocess.dot(X_train_preprocess.T)\n",
    "    K_test = X_test_preprocess.dot(X_train_preprocess.T)\n",
    "    w = solve_svm(K, Y_train, lamb=lamb, kktreg = 1e-9)\n",
    "    n = K.shape[0]\n",
    "    Y_predicted = np.dot(K_test, w[:n]) > 0.\n",
    "    Y_predicted = Y_predicted + 0.0\n",
    "    # result = ((Y_test+1.)/ 2. == np.transpose(Y_predicted))\n",
    "    Y_predicted_train = np.dot(K, w[:n]) > 0.\n",
    "    result_train = ((Y_train+1)/ 2 == np.transpose(Y_predicted_train))\n",
    "    if np.alltrue(Y_predicted):\n",
    "        print(\"Toute les valeurs sont TRUE\")\n",
    "    if np.alltrue(Y_predicted==False):\n",
    "        print(\"Toute les valeurs sont FALSE\")\n",
    "    print(\"lambda = {}\".format(lamb))\n",
    "    print(\"train : {}\".format(np.mean(result_train)))\n",
    "    return Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.52it/s]\n",
      "100%|██████████| 1000/1000 [00:31<00:00, 32.20it/s]\n",
      "100%|██████████| 1000/1000 [00:31<00:00, 31.45it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test0 = to_k_fold(X_valid0, fold1=9, fold2 = 64)\n",
    "X_test1 = to_k_fold(X_valid1, fold1=9, fold2 = 64)\n",
    "X_test2 = to_k_fold(X_valid2, fold1=9, fold2 = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  9.2621e+00  1.2864e+01  5e+03  2e+00  3e+06\n",
      " 1:  7.2937e+00 -2.8847e+02  3e+02  1e-01  2e+05\n",
      " 2:  2.5566e+00 -5.0199e+01  5e+01  2e-02  3e+04\n",
      " 3:  1.6728e+00 -5.7320e+00  7e+00  2e-03  3e+03\n",
      " 4:  1.3318e+00  8.2074e-02  1e+00  2e-04  3e+02\n",
      " 5:  6.3867e-01  5.2630e-01  1e-01  4e-06  8e+00\n",
      " 6:  5.9189e-01  5.6471e-01  3e-02  9e-07  2e+00\n",
      " 7:  5.8054e-01  5.7490e-01  6e-03  1e-07  2e-01\n",
      " 8:  5.7782e-01  5.7717e-01  7e-04  9e-09  2e-02\n",
      " 9:  5.7752e-01  5.7743e-01  9e-05  1e-09  2e-03\n",
      "10:  5.7747e-01  5.7747e-01  4e-06  7e-10  7e-05\n",
      "11:  5.7747e-01  5.7747e-01  8e-08  7e-10  1e-06\n",
      "12:  5.7747e-01  5.7747e-01  2e-09  7e-10  2e-08\n",
      "Optimal solution found.\n",
      "lambda = 1.5\n",
      "train : 0.833\n"
     ]
    }
   ],
   "source": [
    "Y0_t = (Y0 - 0.5) *2\n",
    "w, bias = fit(X_0, Y0_t, lamb=1.)\n",
    "Y_pred0 = predict(w, bias, X_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  6.9083e+00  1.0034e+01  5e+03  2e+00  2e+07\n",
      " 1:  5.5102e+00 -2.2544e+02  2e+02  8e-02  1e+06\n",
      " 2:  1.8893e+00 -2.8892e+01  3e+01  9e-03  1e+05\n",
      " 3:  1.4867e+00 -3.5336e+00  5e+00  1e-03  2e+04\n",
      " 4:  1.1001e+00 -8.0780e-02  1e+00  2e-04  2e+03\n",
      " 5:  4.9247e-01  3.3941e-01  2e-01  1e-05  2e+02\n",
      " 6:  4.2388e-01  3.8429e-01  4e-02  3e-06  4e+01\n",
      " 7:  4.0657e-01  3.9766e-01  9e-03  5e-07  7e+00\n",
      " 8:  4.0255e-01  4.0082e-01  2e-03  8e-08  1e+00\n",
      " 9:  4.0166e-01  4.0152e-01  1e-04  5e-09  8e-02\n",
      "10:  4.0159e-01  4.0158e-01  7e-06  7e-10  3e-03\n",
      "11:  4.0159e-01  4.0159e-01  3e-07  8e-10  1e-04\n",
      "12:  4.0159e-01  4.0159e-01  8e-09  8e-10  2e-06\n",
      "13:  4.0159e-01  4.0159e-01  3e-10  8e-10  2e-08\n",
      "Optimal solution found.\n",
      "lambda = 2.0\n",
      "train : 0.9205\n"
     ]
    }
   ],
   "source": [
    "Y1_t = (Y1 - 0.5) *2\n",
    "w, bias = fit(X_1, Y1_t, lamb=1.)\n",
    "Y_pred1 = predict(w, bias, X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.5420e+01  2.1448e+01  5e+03  2e+00  6e+06\n",
      " 1:  1.0812e+01 -3.7609e+02  4e+02  1e-01  5e+05\n",
      " 2:  2.9521e+00 -5.2604e+01  6e+01  2e-02  6e+04\n",
      " 3:  1.8370e+00 -6.9842e+00  9e+00  2e-03  8e+03\n",
      " 4:  1.5149e+00  1.9806e-01  1e+00  1e-04  5e+02\n",
      " 5:  8.2708e-01  6.2501e-01  2e-01  2e-05  7e+01\n",
      " 6:  7.2171e-01  6.8425e-01  4e-02  3e-06  1e+01\n",
      " 7:  7.0418e-01  6.9742e-01  7e-03  3e-07  1e+00\n",
      " 8:  7.0081e-01  7.0005e-01  8e-04  3e-08  1e-01\n",
      " 9:  7.0044e-01  7.0035e-01  9e-05  3e-09  1e-02\n",
      "10:  7.0039e-01  7.0039e-01  6e-06  7e-10  7e-04\n",
      "11:  7.0039e-01  7.0039e-01  2e-07  8e-10  2e-05\n",
      "12:  7.0039e-01  7.0039e-01  5e-09  8e-10  3e-07\n",
      "13:  7.0039e-01  7.0039e-01  2e-10  8e-10  3e-09\n",
      "Optimal solution found.\n",
      "lambda = 1.8\n",
      "train : 0.769\n"
     ]
    }
   ],
   "source": [
    "Y2_t = (Y2 - 0.5) *2\n",
    "w, bias = fit(X_2, Y2_t, lamb=1.)\n",
    "Y_pred2 = predict(w, bias, X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0 = np.transpose(Y_pred0)[:][0]\n",
    "test1 = np.transpose(Y_pred1)[:][0]\n",
    "test2 = np.transpose(Y_pred2)[:][0]\n",
    "\n",
    "bound = np.concatenate((test0,test1,test2), axis=0).reshape((-1)).astype(int)\n",
    "final = pd.DataFrame(np.arange(3000), columns=['Id'])\n",
    "final['Bound'] = bound\n",
    "final.to_csv('resultk_fold.csv', index= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class LinearKernel():\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.kernel = 'linear'\n",
    "\n",
    "\tdef K_matrix(self, X1, X2=None):\n",
    "\t\tif X2 is None:\n",
    "\t\t\tX2 = X1\n",
    "\t\treturn np.dot(X1, X2.T)\n",
    "    \n",
    "\n",
    "\n",
    "class GaussianKernel():\n",
    "\n",
    "\tdef __init__(self, sigma=1.):\n",
    "\t\tself.kernel = 'gaussian'\n",
    "\t\tself.sigma = sigma\n",
    "\n",
    "\tdef K_matrix(self, X1, X2=None):\n",
    "\t\tif X2 is None:\n",
    "\t\t\tX2 = X1\n",
    "\t\tK = cdist(X1, X2, 'sqeuclidean')\n",
    "\t\tK = np.exp(-K/(2*self.sigma**2))\n",
    "\t\treturn K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "KernelMapping = {\n",
    "    'linear':LinearKernel,\n",
    "    'gaussian':GaussianKernel\n",
    "}\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "class KernelLogisticRegression():\n",
    "\n",
    "    def __init__(self, kernel='linear', lamb=1e-2, maxiter=1e5, threshold=1e-3, **kwargs):\n",
    "        \"\"\"\n",
    "        kernel specifies the type of kernel to use\n",
    "        lamb specifies the regularization parameter\n",
    "        \"\"\"\n",
    "\n",
    "        self.kernel = KernelMapping[kernel](**kwargs)\n",
    "        self.lamb = lamb\n",
    "        self.alpha = None\n",
    "        self.dim = None\n",
    "        self.X_ = None\n",
    "        self.maxiter = maxiter\n",
    "        self.threshold = threshold\n",
    "        self.t = 0\n",
    "\n",
    "    def update_alpha(self, K, Y):\n",
    "        \"\"\"\n",
    "        itertive step to update alpha when training the classifier\n",
    "        \"\"\"\n",
    "        n = K.shape[0]\n",
    "        m = np.dot(K, self.alpha).reshape(-1)\n",
    "        P = -sigmoid(-Y*m)\n",
    "        W = sigmoid(m)*sigmoid(-m)\n",
    "        z = m - P*Y/W\n",
    "\n",
    "        del P, m\n",
    "        W = np.diag(np.sqrt(W.reshape(-1)))\n",
    "\n",
    "        A = np.dot(np.dot(W, K), W) + n*self.lamb*np.eye(n)\n",
    "        A = np.dot(np.dot(W, np.linalg.inv(A)), W)\n",
    "\n",
    "        del W\n",
    "\n",
    "        return np.dot(A, z)\n",
    "\n",
    "    def fit(self, X, Y, verbose=False, return_pred=False):\n",
    "\n",
    "        Y = 2*Y-1\n",
    "\n",
    "        n = X.shape[0]\n",
    "        self.dim = X.shape[1]\n",
    "\n",
    "        if verbose:\n",
    "            t0 = time()\n",
    "\n",
    "        K = self.kernel.K_matrix(X)\n",
    "\n",
    "        if verbose:\n",
    "            print('Kernel matrix computed in {0:.2f} seconds'.format(time()-t0))\n",
    "\n",
    "        \n",
    "        diff = np.infty ## Convergence value\n",
    "        if self.t==0:\n",
    "            self.alpha = np.zeros(n)\n",
    "\n",
    "        while (self.t < self.maxiter and diff > self.threshold):\n",
    "\n",
    "            alpha_new = self.update_alpha(K, Y)\n",
    "\n",
    "            diff = np.sum((self.alpha-alpha_new)**2)\n",
    "\n",
    "            \n",
    "            self.alpha = np.copy(alpha_new)\n",
    "\n",
    "            if verbose:\n",
    "                print('Update difference for alpha:', diff)\n",
    "\n",
    "            self.t += 1\n",
    "\n",
    "        self.X_ = X\n",
    "\n",
    "        if return_pred:\n",
    "            f = np.dot(K, self.alpha)\n",
    "            pred = sigmoid(f)\n",
    "            pred = (pred>0.5).astype(int)\n",
    "            pred = 2*pred - 1\n",
    "            return np.mean(Y==pred)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        K = self.kernel.K_matrix(X, self.X_)\n",
    "        f = np.dot(K, self.alpha)\n",
    "        pred = sigmoid(f)\n",
    "        return (pred>0.5).astype(int)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        Y_test = self.predict(X)\n",
    "        return np.mean(Y==Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb = 10000.0, acc train = 0.574375, acc_test = 0.5125\n",
      "lamb = 11000.0, acc train = 0.574375, acc_test = 0.5125\n",
      "lamb = 12000.0, acc train = 0.574375, acc_test = 0.5125\n",
      "lamb = 13000.0, acc train = 0.574375, acc_test = 0.5125\n",
      "lamb = 14000.0, acc train = 0.574375, acc_test = 0.5125\n",
      "lamb = 15000.0, acc train = 0.574375, acc_test = 0.5125\n",
      "lamb = 16000.0, acc train = 0.574375, acc_test = 0.5125\n",
      "lamb = 17000.0, acc train = 0.574375, acc_test = 0.5125\n",
      "lamb = 18000.0, acc train = 0.574375, acc_test = 0.5125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-f05c37270c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2e4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlog_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKernelLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000.\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lamb = {}, acc train = {}, acc_test = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-546babbf4eee>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, verbose, return_pred)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-047ac725d158>\u001b[0m in \u001b[0;36mK_matrix\u001b[0;34m(self, X1, X2)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mX2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sqeuclidean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.4/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2437\u001b[0m             cdist_fn = getattr(_distance_wrap,\n\u001b[1;32m   2438\u001b[0m                                \"cdist_%s_%s_wrap\" % (metric_name, typ))\n\u001b[0;32m-> 2439\u001b[0;31m             \u001b[0mcdist_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lamb in np.arange(1e4, 2e4, 1e3):\n",
    "    log_kernel = KernelLogisticRegression(kernel='gaussian', lamb=lamb, threshold=1e-3, sigma=1000. )\n",
    "    acc_train = log_kernel.fit(X_train, (Y_train+1.)/2., return_pred=True)\n",
    "    acc_test = (log_kernel.score(X_test, (Y_test+1.)/2.))\n",
    "    print(\"lamb = {}, acc train = {}, acc_test = {}\".format(lamb, acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formal arg: 1\n",
      "another keyword arg: myarg2: two\n",
      "another keyword arg: myarg3: 3\n"
     ]
    }
   ],
   "source": [
    "def test_var_kwargs(farg, **kwargs):\n",
    "    print(\"formal arg:\", farg)\n",
    "    for key in kwargs:\n",
    "        print(\"another keyword arg: %s: %s\" % (key, kwargs[key]))\n",
    "\n",
    "test_var_kwargs(farg=1, myarg2=\"two\", myarg3=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_kuplet_gap(seq, k_tmp, fold=5, k_grams_count=None):\n",
    "    assert fold%2 == 1 or fold ==2, \"fold must be odd\"\n",
    "    fold_size = len(bin(fold)[2:])\n",
    "    fold = bin(fold)[2:]\n",
    "    base_azote = ['A', 'C', 'T', 'G']\n",
    "\n",
    "    if k_grams_count is None:\n",
    "        k_grams_count = dict()\n",
    "\n",
    "    tab = [''.join(i) for i in product(base_azote, repeat=np.sum([int(i) for i in fold]))]\n",
    "    for code in tab:\n",
    "        # print(''.join([code, '_', fold]))\n",
    "        # k_grams_count[''.join([code, '_', fold])] = 0.\n",
    "        # k_tmp[''.join([code, '_', fold])] = 0.\n",
    "        k_grams_count[''.join([code, '_'])] = k_grams_count.get(''.join([code, '_']), 0.)\n",
    "        k_tmp[''.join([code, '_'])] = k_tmp.get(''.join([code, '_']), 0.)\n",
    "\n",
    "    for i in range(len(seq) - fold_size+1):\n",
    "        l = seq[i:(i+fold_size)]\n",
    "        # print(l)\n",
    "        l = ''.join(l[i]*int(fold[i]) for i in range(len(fold)))\n",
    "        # k_grams_count[''.join([l, '_', fold])] += 1./(len(seq) - fold_size+1)\n",
    "        # k_tmp[''.join([l, '_', fold])] += 1.\n",
    "        k_grams_count[''.join([l, '_'])] += 0.9**(len(seq) - fold_size+1) # 1./(len(seq) - fold_size+1)\n",
    "        k_tmp[''.join([l, '_'])] += 1.\n",
    "    return k_grams_count, k_tmp\n",
    "\n",
    "def count_k_fold(sent, k_tmp, fold1 = 9, fold2 = 64):\n",
    "    k_grams_count = dict()\n",
    "    k_tmp = dict()\n",
    "    for fold in np.arange(fold1, fold2, 2):\n",
    "        if(np.sum([int(i) for i in bin(fold)[2:]]) in [7, 8]):\n",
    "            k_grams_count, k_tmp = count_kuplet_gap(sent, k_tmp, fold = fold, k_grams_count=k_grams_count)\n",
    "    return np.array([k_grams_count[key] for key in sorted(k_grams_count)]), np.array([k_tmp[key] for key in sorted(k_tmp)])\n",
    "\n",
    "\n",
    "def to_k_fold(X, fold1=9, fold2=64):\n",
    "    '''\n",
    "    From X (X_raw) compute a sequence X_process using count_k_fold\n",
    "    '''\n",
    "\n",
    "    X_process = []\n",
    "    X_count = []\n",
    "    k_tmp = defaultdict(int)\n",
    "    for sent in tqdm(X):\n",
    "        sent_process, k_tmp = count_k_fold(sent, k_tmp, fold1 = fold1, fold2 = fold2)\n",
    "        X_process.append(sent_process)\n",
    "        X_count.append(k_tmp)\n",
    "\n",
    "    X_process = np.array(X_process) * len(X) * len(X[0])\n",
    "    sum_tmp = np.sum(np.array(X_count), axis=0)\n",
    "\n",
    "    X_process = np.divide(X_process, sum_tmp, out=np.zeros_like(X_process), where=sum_tmp!=0)\n",
    "\n",
    "    return X_process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
