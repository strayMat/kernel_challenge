{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from numba import njit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from numpy import linalg as LA\n",
    "from tqdm import tqdm\n",
    "# from numba import njit\n",
    "\n",
    "from kernel import *\n",
    "\n",
    "# from sklearn import svm\n",
    "\n",
    "from kernel_functions import * # gram_phi, count_kuplet_k, count_kuplet_3\n",
    "from preprocessing import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences shape:  (2000,)\n",
      "sequence first row:  TCCTCAACTTTTATTGGGCCGCTGTGGCACCAGAATCTACGAATGGCGCCCTCTAGAGTTGTGTAAAGAAGTGGCGTCACCTCATTATAAATAAAAGGTTG\n",
      "labels shape (2000,)\n"
     ]
    }
   ],
   "source": [
    "# load all data as the numpy array type\n",
    "#X = pd.read_csv('data/Xtr1_mat50.csv', sep=' ', header=None).values\n",
    "X_raw0 = pd.read_csv('data/Xtr0.csv', sep= ' ', header = None).values.reshape((-1))\n",
    "X_raw1 = pd.read_csv('data/Xtr1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_raw2 = pd.read_csv('data/Xtr2.csv', sep=' ', header=None).values.reshape((-1))\n",
    "\n",
    "# transform to an array of string\n",
    "X_valid0 = pd.read_csv('data/Xte0.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_valid1 = pd.read_csv('data/Xte1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_valid2 = pd.read_csv('data/Xte1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "\n",
    "\n",
    "Y0 = pd.read_csv('data/Ytr0.csv', sep=',', header=0)['Bound'].values\n",
    "Y1 = pd.read_csv('data/Ytr1.csv', sep=',', header=0)['Bound'].values\n",
    "Y2 = pd.read_csv('data/Ytr2.csv', sep=',', header=0)['Bound'].values\n",
    "\n",
    "#print('numerical features shape', X.shape)\n",
    "#print('numerical features first row', X[0])\n",
    "print('sequences shape: ', X_raw0.shape)\n",
    "print('sequence first row: ', X_raw0[0])\n",
    "print('labels shape', Y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "codon2AA = {}\n",
    "codon2AA[\"ATT\"]=\"I\";codon2AA[\"ATC\"]=\"I\";codon2AA[\"ATA\"]=\"I\"\n",
    "codon2AA[\"CTT\"]=\"L\";codon2AA[\"CTC\"]=\"L\";codon2AA[\"CTA\"]=\"L\";codon2AA[\"CTG\"]=\"L\";codon2AA[\"TTA\"]=\"L\";codon2AA[\"TTG\"]=\"L\"\n",
    "codon2AA[\"GTT\"]=\"V\";codon2AA[\"GTC\"]=\"V\";codon2AA[\"GTA\"]=\"V\";codon2AA[\"GTG\"]=\"V\"\n",
    "codon2AA[\"TTT\"]=\"F\";codon2AA[\"TTC\"]=\"F\"\n",
    "codon2AA[\"ATG\"]=\"M\"\n",
    "codon2AA[\"TGT\"]=\"C\";codon2AA[\"TGC\"]=\"C\"\n",
    "codon2AA[\"GCT\"]=\"A\";codon2AA[\"GCC\"]=\"A\";codon2AA[\"GCA\"]=\"A\";codon2AA[\"GCG\"]=\"A\"\n",
    "codon2AA[\"GGT\"]=\"G\";codon2AA[\"GGC\"]=\"G\";codon2AA[\"GGA\"]=\"G\";codon2AA[\"GGG\"]=\"G\"\n",
    "codon2AA[\"CCT\"]=\"P\";codon2AA[\"CCC\"]=\"P\";codon2AA[\"CCA\"]=\"P\";codon2AA[\"CCG\"]=\"P\"\n",
    "codon2AA[\"ACT\"]=\"T\";codon2AA[\"ACC\"]=\"T\";codon2AA[\"ACA\"]=\"T\";codon2AA[\"ACG\"]=\"T\"\n",
    "codon2AA[\"TCT\"]=\"S\";codon2AA[\"TCC\"]=\"S\";codon2AA[\"TCA\"]=\"S\";codon2AA[\"TCG\"]=\"S\";codon2AA[\"AGT\"]=\"S\";codon2AA[\"AGC\"]=\"S\"\n",
    "codon2AA[\"TAT\"]=\"Y\";codon2AA[\"TAC\"]=\"Y\"\n",
    "codon2AA[\"TGG\"]=\"W\"\n",
    "codon2AA[\"CAA\"]=\"Q\";codon2AA[\"CAG\"]=\"Q\"\n",
    "codon2AA[\"AAT\"]=\"N\";codon2AA[\"AAC\"]=\"N\"\n",
    "codon2AA[\"CAT\"]=\"H\";codon2AA[\"CAC\"]=\"H\"\n",
    "codon2AA[\"GAA\"]=\"E\";codon2AA[\"GAG\"]=\"E\"\n",
    "codon2AA[\"GAT\"]=\"D\";codon2AA[\"GAC\"]=\"D\"\n",
    "codon2AA[\"AAA\"]=\"K\";codon2AA[\"AAG\"]=\"K\"\n",
    "codon2AA[\"CGT\"]=\"R\";codon2AA[\"CGC\"]=\"R\";codon2AA[\"CGA\"]=\"R\";codon2AA[\"CGG\"]=\"R\";codon2AA[\"AGA\"]=\"R\";codon2AA[\"AGG\"]=\"R\"\n",
    "codon2AA[\"TAA\"]=\"\";codon2AA[\"TAG\"]=\"\";codon2AA[\"TGA\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sequence(seq):\n",
    "    i=0\n",
    "    tab1 = ''\n",
    "    while(i<len(seq)-2):\n",
    "        code = codon2AA[seq[i] + seq[i+1] + seq[i+2]]\n",
    "        # if(code==''):\n",
    "        #     print(\"stop\") Strategie possible, arrêter la séquence pour les codons stop\n",
    "        tab1 += code\n",
    "        i+=3\n",
    "    i=1\n",
    "    tab2 = ''\n",
    "    while(i<len(seq)-2):\n",
    "        code = codon2AA[seq[i] + seq[i+1] + seq[i+2]]\n",
    "        tab2 += code\n",
    "        # if(code==''):\n",
    "        #     print(\"stop\")\n",
    "        i+=3\n",
    "    i=2\n",
    "    tab3 = ''\n",
    "    while(i<len(seq)-2):\n",
    "        code = codon2AA[seq[i] + seq[i+1] + seq[i+2]]\n",
    "        tab3 += code\n",
    "        # if(code==''):\n",
    "        #     print(\"stop\")\n",
    "        i+=3\n",
    "    \n",
    "    return [tab1, tab2, tab3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernel import *\n",
    "import multiprocessing # import Pool\n",
    "\n",
    "\n",
    "def solve_svm_kernel(X_train, \n",
    "                     X_test, \n",
    "                     Y_train, \n",
    "                     Y_test, \n",
    "                     kernel='k_gram_gaussian', \n",
    "                     k=3, k2=6, \n",
    "                     k1=4,\n",
    "                     m = 2, # maximum mismatch for msimatch kernel\n",
    "                     lamb=0.1, \n",
    "                     gamma=0.1, \n",
    "                     kktreg=1e-9,\n",
    "                     codon = False,\n",
    "                     preprocess_mismatch = None\n",
    "                    ):\n",
    "    \"\"\"\n",
    "    kernel in ['k_gram', 'k_gram_gaussian', 'k_substring', 'local_alignement', 'k_gram_concat', 'k_gram_concat_several']\n",
    "    \"\"\"\n",
    "    assert kernel in ['k_gram', 'k_gram_gaussian', 'k_substring', 'local_alignement',\n",
    "                      'k_gram_concat', 'k_gram_concat_several', 'diMismatch', 'mismatch']\n",
    "    N_train = len(X_train)\n",
    "    N_test = len(X_test)\n",
    "    X_train_process = X_train\n",
    "    X_test_process = X_test\n",
    "    \n",
    "    if codon:\n",
    "        for i in range(N_train):\n",
    "            # print(X_train_process[i])\n",
    "            X_train_process[i] = transform_sequence(X_train_process[i])\n",
    "        for i in tqdm(range(N_test)):\n",
    "            X_test_process[i] = transform_sequence(X_test_process[i])\n",
    "        \n",
    "    if kernel in ['k_gram', 'k_gram_gaussian']:\n",
    "        if codon:\n",
    "            X_train_process = np.array([count_kuplet_k(x[0], k=k) + count_kuplet_k(x[1], k=k) \\\n",
    "                                        + count_kuplet_k(x[2], k=k) for x in X_train_process])\n",
    "            X_test_process = np.array([count_kuplet_k(x[0], k=k) + count_kuplet_k(x[1], k=k) \\\n",
    "                                        + count_kuplet_k(x[2], k=k) for x in X_test_process])\n",
    "        else:\n",
    "            if k == 3:\n",
    "                X_train_process = np.array([count_kuplet_3(x) for x in X_train_process])\n",
    "                X_test_process = np.array([count_kuplet_3(x) for x in X_test_process])\n",
    "            else:\n",
    "                X_train_process = np.array([count_kuplet_k(x,k=k) for x in X_train_process])\n",
    "                X_test_process = np.array([count_kuplet_k(x,k=k) for x in X_test_process])\n",
    "        \n",
    "        # Adding 1 for the sake of the bias\n",
    "        X_train_process = np.concatenate((X_train_process, np.ones((X_train_process.shape[0], 1))), axis=1)\n",
    "        X_test_process = np.concatenate((X_test_process, np.ones((X_test_process.shape[0], 1))), axis=1)\n",
    "    \n",
    "    if kernel=='k_gram_concat':\n",
    "        print(\"building kernel...\")\n",
    "        X_train_process1 = np.array([count_kuplet_3(x) for x in X_train_process])\n",
    "        X_train_process2 = np.array([count_kuplet_k(x, k=k2) for x in X_train_process])\n",
    "        X_train_process = np.concatenate((X_train_process1, X_train_process2), axis=1)\n",
    "        X_test_process1 = np.array([count_kuplet_3(x) for x in X_test_process])\n",
    "        X_test_process2 = np.array([count_kuplet_k(x, k=k2) for x in X_test_process])\n",
    "        X_test_process = np.concatenate((X_test_process1, X_test_process2), axis=1)\n",
    "        \n",
    "        X_train_process = np.concatenate((X_train_process, np.ones((X_train_process.shape[0], 1))), axis=1)\n",
    "        X_test_process = np.concatenate((X_test_process, np.ones((X_test_process.shape[0], 1))), axis=1)\n",
    "    \n",
    "    if kernel=='k_gram_concat_several':\n",
    "        print(\"building kernel...\")\n",
    "        if codon:\n",
    "            X_train_process = np.array([count_kuplet_k(x[0], k=k1) + count_kuplet_k(x[1], k=k1) \\\n",
    "                                        + count_kuplet_k(x[2], k=k1) for x in X_train_process])\n",
    "            X_test_process = np.array([count_kuplet_k(x[0], k=k1) + count_kuplet_k(x[1], k=k1) \\\n",
    "                                        + count_kuplet_k(x[2], k=k1) for x in X_test_process])\n",
    "            for k_tmp in range(k1+1, k2):\n",
    "                X_train_process2 = np.array([count_kuplet_k(x[0], k=k_tmp) + count_kuplet_k(x[1], k=k_tmp) \\\n",
    "                                        + count_kuplet_k(x[2], k=k_tmp) for x in X_train])\n",
    "                X_test_process2 = np.array([count_kuplet_k(x[0], k=k_tmp) + count_kuplet_k(x[1], k=k_tmp) \\\n",
    "                                        + count_kuplet_k(x[2], k=k_tmp) for x in X_test])\n",
    "                X_test_process = np.concatenate((X_test_process, X_test_process2), axis=1)\n",
    "                X_train_process = np.concatenate((X_train_process, X_train_process2), axis=1)\n",
    "            \n",
    "        else :\n",
    "            X_train_process_tmp = np.array([count_kuplet_3(x) for x in X_train_process])\n",
    "            X_test_process_tmp = np.array([count_kuplet_3(x) for x in X_test_process])\n",
    "\n",
    "            for k_tmp in range(k1, k2):\n",
    "                X_train_process2 = np.array([count_kuplet_k(x, k=k_tmp) for x in X_train_process])\n",
    "                X_train_process_tmp = np.concatenate((X_train_process_tmp, X_train_process2), axis=1)\n",
    "                X_test_process2 = np.array([count_kuplet_k(x, k=k_tmp) for x in X_test_process])\n",
    "                X_test_process_tmp = np.concatenate((X_test_process_tmp, X_test_process2), axis=1)\n",
    "        \n",
    "        X_train_process = np.concatenate((X_train_process_tmp, np.ones((X_train_process.shape[0], 1))), axis=1)\n",
    "        X_test_process = np.concatenate((X_test_process_tmp, np.ones((X_test_process.shape[0], 1))), axis=1)\n",
    "        \n",
    "    if kernel in [\"k_gram\", 'k_gram_concat', 'k_gram_concat_several']:\n",
    "        # Computing the Gram-Matrix\n",
    "        K = X_train_process.dot(X_train_process.T)\n",
    "        w = solve_svm(K, Y_train, lamb=lamb, kktreg=kktreg)\n",
    "        K_test = np.dot(X_test_process, np.transpose(X_train_process))\n",
    "    \n",
    "    if kernel==\"k_gram_gaussian\":\n",
    "        # Computing the Gram-Matrix\n",
    "        K = np.array([LA.norm(X_train_process - y, axis=1) for y in X_train_process])\n",
    "        K = np.exp(-K/gamma)\n",
    "        # K = X_train_process.dot(X_train_process.T)\n",
    "        w = solve_svm(K, Y_train, lamb=lamb)\n",
    "        K_test = np.array([LA.norm(X_train_process - y, axis=1) for y in X_test_process])\n",
    "        print(K_test.shape)\n",
    "        K_test = np.exp(-K_test/gamma)\n",
    "    \n",
    "    if kernel=='k_substring':\n",
    "        # Computing the Gram-Matrix\n",
    "        K = np.zeros((N_train, N_train))\n",
    "        X_train_process=[]\n",
    "        X_test_process=[]\n",
    "        for i in tqdm(range(N_train)):\n",
    "            X_train_process.append(transform_sequence(X_train[i]))\n",
    "        for i in tqdm(range(N_test)):\n",
    "            X_test_process.append(transform_sequence(X_test[i]) )\n",
    "        \n",
    "        for i in tqdm(range(len(X_train))):\n",
    "            for j in range(i, len(X_train)):\n",
    "                K[i][j] = K[j][i] = compute_gap_kernel(X_train_process[i][0], X_train_process[j][0], k) + \\\n",
    "                    compute_gap_kernel(X_train_process[i][1], X_train_process[j][1], k) + \\\n",
    "                    compute_gap_kernel(X_train_process[i][2], X_train_process[j][2], k)\n",
    "        w = solve_svm(K, Y_train, lamb=lamb, kktreg=kktreg)\n",
    "        K_test = np.zeros((N_test, N_train))\n",
    "        for i in tqdm(range(len(X_test)), desc=\"Compution testing Kernel\"):\n",
    "            for j in range(len(X_train)):\n",
    "                K_test[i][j] = compute_gap_kernel(X_test[i], X_train[j], k)\n",
    "    \n",
    "    if kernel=='local_alignement':\n",
    "        K = np.zeros((N_train, N_train))\n",
    "        X_train_process=[]\n",
    "        X_test_process=[]\n",
    "        for i in tqdm(range(N_train)):\n",
    "            X_train_process.append(transform_sequence(X_train[i]))\n",
    "        for i in tqdm(range(N_test)):\n",
    "            X_test_process.append(transform_sequence(X_test[i]) )\n",
    "        \n",
    "        for i in tqdm(range(len(X_train))):\n",
    "            for j in range(i, len(X_train)):\n",
    "                K[i][j] = K[j][i] = LA_kernel(X_train_process[i][0], X_train_process[j][0]) + \\\n",
    "                    LA_kernel(X_train_process[i][1], X_train_process[j][1]) + \\\n",
    "                    LA_kernel(X_train_process[i][2], X_train_process[j][2])\n",
    "        w = solve_svm(K, Y_train, lamb=lamb, kktreg=kktreg)\n",
    "        K_test = np.zeros((N_test, N_train))\n",
    "        for i in tqdm(range(len(X_test)), desc=\"Compution testing Kernel\"):\n",
    "            for j in range(len(X_train)):\n",
    "                K_test[i][j] = LA_kernel(X_test[i], X_train[j])\n",
    "    \n",
    "    if kernel=='mismatch':\n",
    "        # compute all possible k_gram from ATGC\n",
    "        gramList, gramDict = k_gramGen(k)    \n",
    "        if (EDITDIST is None):\n",
    "            # compute dynamically the mismatch distances for all possible k_gram of the alphabet\n",
    "            editDist = dynMismatchDist(k, gramList = gramList, gramDict = gramDict)\n",
    "        else:\n",
    "            editDist = EDITDIST\n",
    "        # compute the features \n",
    "        if preprocess_mismatch is None:\n",
    "            X_train_preprocess = mismatchFeatures(X_train, k = k, m = m, \n",
    "                                                 gramList = gramList, gramDict = gramDict, mismatchDist = editDist)\n",
    "            X_test_preprocess = mismatchFeatures(X_test, k = k, m = m, \n",
    "                                                 gramList = gramList, gramDict = gramDict, mismatchDist = editDist)\n",
    "        else :\n",
    "            (X_train_preprocess, X_test_preprocess) = preprocess_mismatch\n",
    "        # Adding 1 for the sake of the bias\n",
    "        X_train_preprocess = np.concatenate((X_train_preprocess, np.ones((X_train_preprocess.shape[0], 1))), axis=1)\n",
    "        X_test_preprocess = np.concatenate((X_test_preprocess, np.ones((X_test_preprocess.shape[0], 1))), axis=1)\n",
    "    \n",
    "        # compute gram matrices from features and solve svm\n",
    "        K = X_train_preprocess.dot(X_train_preprocess.T)\n",
    "        K_test = X_test_preprocess.dot(X_train_preprocess.T)\n",
    "        w = solve_svm(K, Y_train, lamb=lamb, kktreg = kktreg)\n",
    "\n",
    "    \n",
    "    if kernel=='diMismatch':\n",
    "        # compute all possible k_gram from ATGC\n",
    "        gramList, gramDict = k_gramGen(k)    \n",
    "        if (EDITDIST is None):\n",
    "            # compute dynamically the diMismatch distances for all possible k_gram of the alphabet\n",
    "            editDist = dynDiMismatchDist(k, gramList = gramList, gramDict = gramDict)\n",
    "        else:\n",
    "            editDist = EDITDIST\n",
    "        # compute the features \n",
    "        if preprocess_mismatch is None:\n",
    "            X_train_preprocess = diMismatchFeatures(X_train, k = k, m = m, \n",
    "                                             gramList = gramList, gramDict = gramDict, diMismatchDist = editDist)\n",
    "            X_test_preprocess = diMismatchFeatures(X_test, k = k, m = m, \n",
    "                                                 gramList = gramList, gramDict = gramDict, diMismatchDist = editDist)\n",
    "        else :\n",
    "            (X_train_preprocess, X_test_preprocess) = preprocess_mismatch\n",
    "        \n",
    "        # Adding 1 for the sake of the bias\n",
    "        X_train_preprocess = np.concatenate((X_train_preprocess, np.ones((X_train_preprocess.shape[0], 1))), axis=1)\n",
    "        X_test_preprocess = np.concatenate((X_test_preprocess, np.ones((X_test_preprocess.shape[0], 1))), axis=1)\n",
    "    \n",
    "        # compute gram matrices from features and solve svm\n",
    "        K = X_train_preprocess.dot(X_train_preprocess.T)\n",
    "        K_test = X_test_preprocess.dot(X_train_preprocess.T)\n",
    "        w = solve_svm(K, Y_train, lamb=lamb, kktreg=kktreg)\n",
    "\n",
    "        \n",
    "    n = K.shape[0]\n",
    "    Y_predicted = np.dot(K_test, w[:n]) > 0.\n",
    "    result = ((Y_test+1.)/ 2. == np.transpose(Y_predicted))\n",
    "    Y_predicted_train = np.dot(K, w[:n]) > 0.\n",
    "    result_train = ((Y_train+1)/ 2 == np.transpose(Y_predicted_train))\n",
    "    if np.alltrue(Y_predicted):\n",
    "        print(\"Toute les valeurs sont TRUE\")\n",
    "    if np.alltrue(Y_predicted==False):\n",
    "        print(\"Toute les valeurs sont FALSE\")\n",
    "    return np.mean(result), np.mean(result_train)\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 1.  0.  1.  2.  3.  4.]\n",
      " [ 2.  1.  2.  3.  4.  3.]\n",
      " [ 3.  2.  3.  4.  5.  4.]\n",
      " [ 4.  3.  4.  5.  6.  5.]\n",
      " [ 5.  4.  5.  6.  5.  6.]\n",
      " [ 6.  5.  4.  5.  6.  7.]]\n"
     ]
    }
   ],
   "source": [
    "def edit_distance(str1, str2):\n",
    "    \"\"\"\n",
    "    Compute the Edit Distance between str1 and str2.\n",
    "    Return the number of insertion/deletion/substitution\n",
    "    \"\"\"\n",
    "    n = len(str1)\n",
    "    m = len(str2)\n",
    "    table_str = np.zeros((n+1,m+1))\n",
    "\n",
    "    table_str[0, :]=np.arange(m+1)\n",
    "    table_str[:, 0] = np.arange(n+1)\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            if(str1[i-1] == str2[j-1]):\n",
    "                table_str[i, j] = min(table_str[i-1, j] + 1, table_str[i, j-1] + 1, table_str[i-1, j-1]) \n",
    "            else:\n",
    "                table_str[i, j] = min(table_str[i-1, j] + 1, table_str[i, j-1] + 1, table_str[i-1, j-1]+2) \n",
    "                \n",
    "    return table_str\n",
    "\n",
    "X1 = 'ACCCTG'\n",
    "X2 = 'AGGTC'\n",
    "print(edit_distance(X1, X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (1800,)\n",
      "test shape (200,)\n",
      "train shape (1800,)\n",
      "test shape (200,)\n",
      "train shape (1800,)\n",
      "test shape (200,)\n"
     ]
    }
   ],
   "source": [
    "# With Cross validation\n",
    "\n",
    "X_train0, Y_train0, X_test0, Y_test0 = preprocessing(X_raw0, Y0, percent=0.9)\n",
    "X_train1, Y_train1, X_test1, Y_test1 = preprocessing(X_raw1, Y1, percent=0.9)\n",
    "X_train2, Y_train2, X_test2, Y_test2 = preprocessing(X_raw2, Y2, percent=0.9)\n",
    "print('train shape', X_train0.shape)\n",
    "print('test shape', X_test0.shape)\n",
    "\n",
    "print('train shape', X_train1.shape)\n",
    "print('test shape', X_test1.shape)\n",
    "\n",
    "print('train shape', X_train2.shape)\n",
    "print('test shape', X_test2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,\n",
       "       -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,\n",
       "       -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
       "       -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "        1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,\n",
       "        1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1600)\n",
      "(1600, 400)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.6004e+01  2.1983e+01  4e+03  2e+00  9e+06\n",
      " 1:  1.1446e+01 -3.8336e+02  4e+02  2e-01  9e+05\n",
      " 2:  3.2875e+00 -7.1415e+01  8e+01  3e-02  1e+05\n",
      " 3:  1.9307e+00 -7.0436e+00  9e+00  3e-03  2e+04\n",
      " 4:  1.6138e+00 -5.4699e-01  2e+00  5e-04  3e+03\n",
      " 5:  1.0205e+00  6.4786e-01  4e-01  1e-09  2e-08\n",
      " 6:  7.8088e-01  7.1427e-01  7e-02  1e-09  1e-08\n",
      " 7:  7.4680e-01  7.3438e-01  1e-02  9e-10  4e-09\n",
      " 8:  7.4048e-01  7.3859e-01  2e-03  9e-10  1e-09\n",
      " 9:  7.3945e-01  7.3932e-01  1e-04  9e-10  4e-10\n",
      "10:  7.3938e-01  7.3937e-01  8e-06  9e-10  1e-10\n",
      "11:  7.3938e-01  7.3938e-01  2e-07  9e-10  2e-11\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "# With the file computed with c++\n",
    "ker_train = pd.read_csv('ker_train_X2.csv', sep=',', header=None).values\n",
    "ker_test = pd.read_csv('ker_test_X2.csv', sep=',', header=None).values\n",
    "size1 = ker_train.shape[0]\n",
    "ker_train = ker_train[:, :size1]#  + np.ones((size1, size1))\n",
    "print(ker_train.shape)\n",
    "size2 = ker_test.shape[1] - 1\n",
    "ker_test = ker_test[:, :(size2)]#  + np.ones((size1, size2))\n",
    "print(ker_test.shape)\n",
    "\n",
    "w = solve_svm(ker_train, Y2[:size1]*2 - 1, lamb=1.3, kktreg=1e-9)\n",
    "Y_predicted = np.dot(np.transpose(ker_test), w[:size1]) > 0.\n",
    "if np.alltrue(Y_predicted==False):\n",
    "    print(\"Toute les valeurs sont FALSE\")\n",
    "if np.alltrue(Y_predicted):\n",
    "    print(\"Toute les valeurs sont TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 0.723125\n",
      "test : 0.615\n"
     ]
    }
   ],
   "source": [
    "result = (Y2[size1:(size1+size2)] == Y_predicted)\n",
    "Y_predicted_train = np.dot(np.transpose(ker_train), w[:size1]) > 0.\n",
    "result_train = (Y2[:size1] == np.transpose(Y_predicted_train))\n",
    "if np.alltrue(Y_predicted):\n",
    "    print(\"Toute les valeurs sont TRUE\")\n",
    "if np.alltrue(Y_predicted==False):\n",
    "    print(\"Toute les valeurs sont FALSE\")\n",
    "# return np.mean(result), np.mean(result_train)\n",
    "print(\"train : {}\".format(np.mean(Y_predicted_train.reshape((-1)) == Y2[0:size1])))\n",
    "print(\"test : {}\".format(np.mean(Y_predicted.reshape((-1)) == Y2[size1:(size1+size2)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 8654.46it/s]\n",
      "100%|██████████| 256/256 [00:00<00:00, 3033.72it/s]\n",
      "100%|██████████| 1024/1024 [00:01<00:00, 856.99it/s]\n",
      "100%|██████████| 4096/4096 [00:20<00:00, 202.57it/s]\n",
      "100%|██████████| 16384/16384 [05:40<00:00, 48.07it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 7\n",
    "#for mismatch kernel\n",
    "#EDITDIST = dynMismatchDist(k)\n",
    "#for diMismatch kernel\n",
    "EDITDIST = dynDiMismatchDist(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16384, 16384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDITDIST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Mismatch table for substrings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [00:34<00:00, 51.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Mismatch table for substrings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 59.83it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 7\n",
    "m = 3\n",
    "gramList, gramDict = k_gramGen(k)\n",
    "editDist = EDITDIST\n",
    "X_train_preprocess = mismatchFeatures(X_train0, k = k, m = m, \n",
    "                            gramList = gramList, gramDict = gramDict, mismatchDist = editDist)\n",
    "X_test_preprocess = mismatchFeatures(X_test0, k = k, m = m, \n",
    "                            gramList = gramList, gramDict = gramDict, mismatchDist = editDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.1750e+00  3.2409e+00  4e+03  1e+00  8e+06\n",
      " 1:  3.0636e+00 -7.1418e+01  8e+01  3e-02  2e+05\n",
      " 2:  1.7796e+00 -1.3578e+01  2e+01  6e-03  3e+04\n",
      " 3:  1.3485e+00 -1.2796e+00  3e+00  7e-04  4e+03\n",
      " 4:  8.8506e-01  3.1855e-01  6e-01  7e-05  4e+02\n",
      " 5:  5.2499e-01  4.5201e-01  7e-02  8e-06  5e+01\n",
      " 6:  4.9018e-01  4.7585e-01  1e-02  1e-06  6e+00\n",
      " 7:  4.8309e-01  4.8067e-01  2e-03  1e-07  8e-01\n",
      " 8:  4.8183e-01  4.8154e-01  3e-04  1e-08  8e-02\n",
      " 9:  4.8167e-01  4.8165e-01  2e-05  8e-10  5e-03\n",
      "10:  4.8166e-01  4.8166e-01  5e-07  7e-10  1e-04\n",
      "11:  4.8166e-01  4.8166e-01  1e-08  7e-10  1e-06\n",
      "12:  4.8166e-01  4.8166e-01  2e-10  7e-10  1e-08\n",
      "Optimal solution found.\n",
      "accuracy for train : 0.8666666666666667\n",
      "accuracy for test : 0.74\n"
     ]
    }
   ],
   "source": [
    "acc_test0, acc_train0 = solve_svm_kernel(X_train0,\n",
    "                                       X_test0,\n",
    "                                       Y_train0,\n",
    "                                       Y_test0,\n",
    "                                       kernel='diMismatch',\n",
    "                                       k = 7, m = 3,\n",
    "                                       lamb=1.4,\n",
    "                                       preprocess_mismatch = (X_train_preprocess, X_test_preprocess)\n",
    "                                        )\n",
    "\n",
    "print('accuracy for train : {}'.format(acc_train0))\n",
    "print('accuracy for test : {}'.format(acc_test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.5654e+00  2.6007e+00  4e+03  1e+00  8e+06\n",
      " 1:  2.5040e+00 -6.1180e+01  6e+01  2e-02  1e+05\n",
      " 2:  1.6498e+00 -1.0611e+01  1e+01  5e-03  3e+04\n",
      " 3:  1.2918e+00 -1.1307e+00  2e+00  6e-04  4e+03\n",
      " 4:  8.3016e-01  2.8329e-01  5e-01  7e-05  4e+02\n",
      " 5:  4.8517e-01  4.1309e-01  7e-02  8e-06  5e+01\n",
      " 6:  4.4996e-01  4.3588e-01  1e-02  1e-06  6e+00\n",
      " 7:  4.4257e-01  4.4061e-01  2e-03  1e-07  7e-01\n",
      " 8:  4.4149e-01  4.4134e-01  2e-04  7e-09  4e-02\n",
      " 9:  4.4141e-01  4.4140e-01  7e-06  6e-10  2e-03\n",
      "10:  4.4141e-01  4.4141e-01  2e-07  7e-10  3e-05\n",
      "11:  4.4141e-01  4.4141e-01  9e-09  7e-10  4e-07\n",
      "12:  4.4141e-01  4.4141e-01  5e-10  7e-10  5e-09\n",
      "Optimal solution found.\n",
      "accuracy for train : 0.8861111111111111\n",
      "accuracy for test : 0.735\n"
     ]
    }
   ],
   "source": [
    "acc_test0, acc_train0 = solve_svm_kernel(X_train0,\n",
    "                                       X_test0,\n",
    "                                       Y_train0,\n",
    "                                       Y_test0,\n",
    "                                       kernel='diMismatch',\n",
    "                                       k = 7, m = 3,\n",
    "                                       lamb=1.,\n",
    "                                       preprocess_mismatch = (X_train_preprocess, X_test_preprocess)\n",
    "                                        )\n",
    "\n",
    "print('accuracy for train : {}'.format(acc_train0))\n",
    "print('accuracy for test : {}'.format(acc_test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.7187e+00  2.7608e+00  4e+03  1e+00  8e+06\n",
      " 1:  2.6462e+00 -6.3779e+01  7e+01  3e-02  1e+05\n",
      " 2:  1.6856e+00 -1.1388e+01  1e+01  5e-03  3e+04\n",
      " 3:  1.3086e+00 -1.1755e+00  2e+00  6e-04  4e+03\n",
      " 4:  8.4650e-01  2.9260e-01  6e-01  7e-05  4e+02\n",
      " 5:  4.9708e-01  4.2407e-01  7e-02  8e-06  5e+01\n",
      " 6:  4.6092e-01  4.4775e-01  1e-02  1e-06  5e+00\n",
      " 7:  4.5397e-01  4.5227e-01  2e-03  9e-08  5e-01\n",
      " 8:  4.5305e-01  4.5291e-01  1e-04  5e-09  3e-02\n",
      " 9:  4.5297e-01  4.5297e-01  5e-06  7e-10  7e-04\n",
      "10:  4.5297e-01  4.5297e-01  2e-07  7e-10  1e-05\n",
      "11:  4.5297e-01  4.5297e-01  8e-09  7e-10  2e-07\n",
      "12:  4.5297e-01  4.5297e-01  4e-10  7e-10  3e-09\n",
      "Optimal solution found.\n",
      "accuracy for train : 0.8777777777777778\n",
      "accuracy for test : 0.74\n"
     ]
    }
   ],
   "source": [
    "acc_test0, acc_train0 = solve_svm_kernel(X_train0,\n",
    "                                       X_test0,\n",
    "                                       Y_train0,\n",
    "                                       Y_test0,\n",
    "                                       kernel='diMismatch',\n",
    "                                       k = 7, m = 3,\n",
    "                                       lamb=1.1,\n",
    "                                       preprocess_mismatch = (X_train_preprocess, X_test_preprocess)\n",
    "                                        )\n",
    "\n",
    "print('accuracy for train : {}'.format(acc_train0))\n",
    "print('accuracy for test : {}'.format(acc_test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Mismatch table for substrings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [00:35<00:00, 50.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Mismatch table for substrings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 52.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  7.8055e-01  1.7982e+00  4e+03  1e+00  3e+05\n",
      " 1:  1.7495e+00 -5.6576e+01  6e+01  2e-02  6e+03\n",
      " 2:  1.3719e+00 -8.6263e+00  1e+01  4e-03  9e+02\n",
      " 3:  1.1753e+00 -1.3450e+00  3e+00  7e-04  2e+02\n",
      " 4:  7.4299e-01  1.6067e-01  6e-01  7e-05  2e+01\n",
      " 5:  3.6101e-01  2.8602e-01  7e-02  8e-06  2e+00\n",
      " 6:  3.2262e-01  3.0789e-01  1e-02  1e-06  3e-01\n",
      " 7:  3.1471e-01  3.1284e-01  2e-03  1e-07  3e-02\n",
      " 8:  3.1365e-01  3.1353e-01  1e-04  5e-09  1e-03\n",
      " 9:  3.1358e-01  3.1358e-01  6e-06  5e-10  3e-05\n",
      "10:  3.1358e-01  3.1358e-01  3e-07  5e-10  7e-07\n",
      "11:  3.1358e-01  3.1358e-01  2e-08  5e-10  1e-08\n",
      "Optimal solution found.\n",
      "accuracy for train : 0.9694444444444444\n",
      "accuracy for test : 0.88\n"
     ]
    }
   ],
   "source": [
    "acc_test1, acc_train1 = solve_svm_kernel(X_train1, \n",
    "                                       X_test1, \n",
    "                                       Y_train1, \n",
    "                                       Y_test1, \n",
    "                                       kernel='diMismatch', \n",
    "                                       k=7, m = 1,\n",
    "                                       lamb=0.2)\n",
    "\n",
    "print('accuracy for train : {}'.format(acc_train1))\n",
    "print('accuracy for test : {}'.format(acc_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building kernel...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0133e+00  2.0344e+00  4e+03  1e+00  4e+05\n",
      " 1:  1.9769e+00 -5.8713e+01  6e+01  2e-02  7e+03\n",
      " 2:  1.5141e+00 -1.0281e+01  1e+01  4e-03  1e+03\n",
      " 3:  1.2451e+00 -8.7749e-01  2e+00  5e-04  2e+02\n",
      " 4:  7.5758e-01  2.8568e-01  5e-01  5e-05  2e+01\n",
      " 5:  4.4008e-01  3.7717e-01  6e-02  6e-06  2e+00\n",
      " 6:  4.0572e-01  3.9210e-01  1e-02  1e-06  3e-01\n",
      " 7:  3.9748e-01  3.9560e-01  2e-03  1e-07  4e-02\n",
      " 8:  3.9629e-01  3.9612e-01  2e-04  9e-09  3e-03\n",
      " 9:  3.9618e-01  3.9617e-01  7e-06  6e-10  9e-05\n",
      "10:  3.9618e-01  3.9618e-01  2e-07  6e-10  2e-06\n",
      "11:  3.9618e-01  3.9618e-01  8e-09  6e-10  3e-08\n",
      "Optimal solution found.\n",
      "accuracy for train : 0.9216666666666666\n",
      "accuracy for test : 0.645\n"
     ]
    }
   ],
   "source": [
    "acc_test2, acc_train2 = solve_svm_kernel(X_train2, \n",
    "                                       X_test2, \n",
    "                                       Y_train2, \n",
    "                                       Y_test2, \n",
    "                                       kernel='k_gram_concat_several',\n",
    "                                       k1 = 3, k2=7, m = 4,\n",
    "                                       lamb = 0.03)\n",
    "\n",
    "print('accuracy for train : {}'.format(acc_train2))\n",
    "print('accuracy for test : {}'.format(acc_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters found for k_gram kernel\n",
    "#### k = 3\n",
    "* Set0: lambda=1e-3, gamma = 5 (gaussian), score = 0.68\n",
    "* Set1: lambda=0.01, score = \n",
    "* Set2: lambda= 1e-5, score = \n",
    "\n",
    "#### k = 6\n",
    "\n",
    "* Set0: lamda=0.04 , score = 0.79 (on test)\n",
    "* Set1: lambda=0.01, score= 0.85 (on test)\n",
    "* Set2: lambda= 1e-1, score = 0.6875 (on test)\n",
    "\n",
    "#### k=3 et k=6 (concatenate)\n",
    "\n",
    "* Set0: lamda=0.04, score = 0.7425 (on test)\n",
    "* Set1: lambda=0.05, score = 0.89 (on test)\n",
    "\n",
    "#### k = 3,4,5,6 (concatenate)\n",
    "\n",
    "* Set1: lambda=0.05, score = \n",
    "\n",
    "### mismatch kernel\n",
    "\n",
    "* Set0: lambda = 1, k = 6, m = 2, score = 0.74\n",
    "* Set1: lambda = 0.04, k = 6, m = 4, score = 0.85 \n",
    "* Set2: lambda = 0.04, k = 6 , m = 4, score = 0.645\n",
    "\n",
    "### diMismatch kernel\n",
    "\n",
    "* Set0: lambda = 0.1, k = 6, m = 3, score = 0.75\n",
    "* Set1: lambda = 0.001, k = 6, m = 1, score = 0.83 \n",
    "* Set2: lambda = 0.1, k = 6 , m = 2, score = 0.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def solve_svm_test(X_train, \n",
    "                   X_test, \n",
    "                   Y_train, \n",
    "                   kernel='k_gram_gaussian', \n",
    "                   k=3, k2=6, \n",
    "                   lamb=0.1, \n",
    "                   m = 3,\n",
    "                   gamma=0.1, \n",
    "                   kktreg=1e-9):\n",
    "    \"\"\"\n",
    "    kernel in [k_gram, k_gram_gaussian, k_gram_concat, k_gram_concat_several]\n",
    "    \"\"\"\n",
    "    Y_train_process = (Y_train-0.5) * 2\n",
    "    if kernel in ['k_gram', 'k_gram_gaussian']:\n",
    "        if k == 3:\n",
    "            X_train_process = np.array([count_kuplet_3(x) for x in X_train])\n",
    "            X_test_process = np.array([count_kuplet_3(x) for x in X_test])\n",
    "        else:\n",
    "            X_train_process = np.array([count_kuplet_k(x,k=k) for x in X_train])\n",
    "            X_test_process = np.array([count_kuplet_k(x,k=k) for x in X_test])\n",
    "        \n",
    "        # Adding 1 for the sake of the bias\n",
    "        X_train_process = np.concatenate((X_train_process, np.ones((X_train_process.shape[0], 1))), axis=1)\n",
    "        X_test_process = np.concatenate((X_test_process, np.ones((X_test_process.shape[0], 1))), axis=1)\n",
    "    \n",
    "      \n",
    "    if kernel=='k_gram_concat':\n",
    "        print(\"building kernel...\")\n",
    "        X_train_process1 = np.array([count_kuplet_3(x) for x in X_train])\n",
    "        X_train_process2 = np.array([count_kuplet_k(x, k=k2) for x in X_train])\n",
    "        X_train_process = np.concatenate((X_train_process1, X_train_process2), axis=1)\n",
    "        X_test_process1 = np.array([count_kuplet_3(x) for x in X_test])\n",
    "        X_test_process2 = np.array([count_kuplet_k(x, k=k2) for x in X_test])\n",
    "        X_test_process = np.concatenate((X_test_process1, X_test_process2), axis=1)\n",
    "        \n",
    "        X_train_process = np.concatenate((X_train_process, np.ones((X_train_process.shape[0], 1))), axis=1)\n",
    "        X_test_process = np.concatenate((X_test_process, np.ones((X_test_process.shape[0], 1))), axis=1)\n",
    "    \n",
    "    if kernel=='k_gram_concat_several':\n",
    "        print(\"building kernel...\")\n",
    "        X_train_process = np.array([count_kuplet_3(x) for x in X_train])\n",
    "        X_test_process = np.array([count_kuplet_3(x) for x in X_test])\n",
    "        \n",
    "        for k_tmp in range(4, k2):\n",
    "            X_train_process2 = np.array([count_kuplet_k(x, k=k_tmp) for x in X_train])\n",
    "            X_train_process = np.concatenate((X_train_process, X_train_process2), axis=1)\n",
    "            X_test_process2 = np.array([count_kuplet_k(x, k=k_tmp) for x in X_test])\n",
    "            X_test_process = np.concatenate((X_test_process, X_test_process2), axis=1)\n",
    "        \n",
    "        X_train_process = np.concatenate((X_train_process, np.ones((X_train_process.shape[0], 1))), axis=1)\n",
    "        X_test_process = np.concatenate((X_test_process, np.ones((X_test_process.shape[0], 1))), axis=1)\n",
    "    \n",
    "        \n",
    "    if kernel in [\"k_gram\", 'k_gram_concat', 'k_gram_concat_several']:\n",
    "        # Computing the Gram-Matrix\n",
    "        K = X_train_process.dot(X_train_process.T)\n",
    "        w = solve_svm(K, Y_train_process, lamb=lamb, kktreg=kktreg)\n",
    "        K_test = np.dot(X_test_process, np.transpose(X_train_process))\n",
    "    \n",
    "    if kernel==\"k_gram_gaussian\":\n",
    "        # Computing the Gram-Matrix\n",
    "        K = np.array([LA.norm(X_train_process - y, axis=1) for y in X_train_process])\n",
    "        K = np.exp(-K/gamma)\n",
    "        # K = X_train_process.dot(X_train_process.T)\n",
    "        w = solve_svm(K, Y_train_process, lamb=lamb)\n",
    "        K_test = np.array([LA.norm(X_train_process - y, axis=1) for y in X_test_process])\n",
    "        K_test = np.exp(-K_test/gamma)\n",
    "        \n",
    "    if kernel=='mismatch':\n",
    "        # compute all possible k_gram from ATGC\n",
    "        gramList, gramDict = k_gramGen(k)    \n",
    "        if (EDITDIST is None):\n",
    "            # compute dynamically the mismatch distances for all possible k_gram of the alphabet\n",
    "            editDist = dynMismatchDist(k, gramList = gramList, gramDict = gramDict)\n",
    "        else:\n",
    "            editDist = EDITDIST\n",
    "        # compute the features \n",
    "        X_train_preprocess = mismatchFeatures(X_train, k = k, m = m, \n",
    "                                             gramList = gramList, gramDict = gramDict, mismatchDist = editDist)\n",
    "        X_test_preprocess = mismatchFeatures(X_test, k = k, m = m, \n",
    "                                             gramList = gramList, gramDict = gramDict, mismatchDist = editDist)\n",
    "        \n",
    "        # Adding 1 for the sake of the bias\n",
    "        X_train_preprocess = np.concatenate((X_train_preprocess, np.ones((X_train_preprocess.shape[0], 1))), axis=1)\n",
    "        X_test_preprocess = np.concatenate((X_test_preprocess, np.ones((X_test_preprocess.shape[0], 1))), axis=1)\n",
    "    \n",
    "        # compute gram matrices from features and solve svm\n",
    "        K = X_train_preprocess.dot(X_train_preprocess.T)\n",
    "        K_test = X_test_preprocess.dot(X_train_preprocess.T)\n",
    "        w = solve_svm(K, Y_train_process, lamb=lamb, kktreg = kktreg)\n",
    "\n",
    "    \n",
    "    if kernel=='diMismatch':\n",
    "        # compute all possible k_gram from ATGC\n",
    "        gramList, gramDict = k_gramGen(k)    \n",
    "        if (EDITDIST is None):\n",
    "            # compute dynamically the diMismatch distances for all possible k_gram of the alphabet\n",
    "            editDist = dynDiMismatchDist(k, gramList = gramList, gramDict = gramDict)\n",
    "        else:\n",
    "            editDist = EDITDIST\n",
    "        # compute the features \n",
    "        X_train_preprocess = diMismatchFeatures(X_train, k = k, m = m, \n",
    "                                             gramList = gramList, gramDict = gramDict, diMismatchDist = editDist)\n",
    "        X_test_preprocess = diMismatchFeatures(X_test, k = k, m = m, \n",
    "                                             gramList = gramList, gramDict = gramDict, diMismatchDist = editDist)\n",
    "        # Adding 1 for the sake of the bias\n",
    "        X_train_preprocess = np.concatenate((X_train_preprocess, np.ones((X_train_preprocess.shape[0], 1))), axis=1)\n",
    "        X_test_preprocess = np.concatenate((X_test_preprocess, np.ones((X_test_preprocess.shape[0], 1))), axis=1)\n",
    "    \n",
    "        # compute gram matrices from features and solve svm\n",
    "        K = X_train_preprocess.dot(X_train_preprocess.T)\n",
    "        K_test = X_test_preprocess.dot(X_train_preprocess.T)\n",
    "        w = solve_svm(K, Y_train_process, lamb=lamb, kktreg=kktreg)\n",
    "    \n",
    "    n = K.shape[0]\n",
    "    Y_predicted = np.dot(K_test, w[:n]) > 0.\n",
    "    Y_predicted = (Y_predicted + 0.)\n",
    "    Y_predicted_train = np.dot(K, w[:n]) > 0.\n",
    "    result_train = (Y_train == np.transpose(Y_predicted_train))\n",
    "    print('accuracy on train : {}'.format(np.mean(result_train)))\n",
    "    # result = ((Y_test+1)/ 2 == np.transpose(Y_predicted))\n",
    "    \n",
    "    return np.transpose(Y_predicted) # , np.transpose(Y_predicted_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (2000,)\n",
      "train shape 2 : (2000,)\n",
      "test shape : (1000,)\n",
      "building kernel...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3933e+00  2.4457e+00  4e+03  1e+00  2e+05\n",
      " 1:  2.3072e+00 -7.7379e+01  8e+01  3e-02  4e+03\n",
      " 2:  1.5181e+00 -1.0879e+01  1e+01  4e-03  6e+02\n",
      " 3:  1.2311e+00 -1.2345e+00  2e+00  6e-04  8e+01\n",
      " 4:  7.7800e-01  1.7185e-01  6e-01  8e-05  1e+01\n",
      " 5:  4.0635e-01  3.3032e-01  8e-02  9e-06  1e+00\n",
      " 6:  3.6744e-01  3.5152e-01  2e-02  1e-06  2e-01\n",
      " 7:  3.5926e-01  3.5614e-01  3e-03  2e-07  3e-02\n",
      " 8:  3.5751e-01  3.5714e-01  4e-04  2e-08  3e-03\n",
      " 9:  3.5729e-01  3.5727e-01  2e-05  9e-10  1e-04\n",
      "10:  3.5728e-01  3.5728e-01  6e-07  7e-10  3e-06\n",
      "11:  3.5728e-01  3.5728e-01  2e-08  7e-10  4e-08\n",
      "Optimal solution found.\n",
      "accuracy on train : 0.9225\n"
     ]
    }
   ],
   "source": [
    "print('train shape : {}'.format(X_raw0.shape))\n",
    "print('train shape 2 : {}'.format(Y0.shape))\n",
    "print('test shape : {}'.format(X_valid0.shape))\n",
    "\n",
    "Y_predict0 = solve_svm_test(X_raw0, \n",
    "                           X_valid0, \n",
    "                           Y0, \n",
    "                           kernel='k_gram_concat_several', \n",
    "                           k2=7, lamb=.04, gamma=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (2000,)\n",
      "train shape 2 : (2000,)\n",
      "test shape : (1000,)\n",
      "Building Mismatch table for substrings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:40<00:00, 48.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Mismatch table for substrings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 53.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  8.8901e-01  1.9110e+00  4e+03  1e+00  4e+05\n",
      " 1:  1.8516e+00 -6.6116e+01  7e+01  2e-02  7e+03\n",
      " 2:  1.3995e+00 -8.9214e+00  1e+01  3e-03  1e+03\n",
      " 3:  1.1951e+00 -1.4962e+00  3e+00  6e-04  2e+02\n",
      " 4:  7.6591e-01  1.3720e-01  6e-01  7e-05  2e+01\n",
      " 5:  3.6199e-01  2.8678e-01  8e-02  8e-06  2e+00\n",
      " 6:  3.2452e-01  3.1041e-01  1e-02  1e-06  3e-01\n",
      " 7:  3.1745e-01  3.1533e-01  2e-03  8e-08  2e-02\n",
      " 8:  3.1623e-01  3.1609e-01  1e-04  4e-09  1e-03\n",
      " 9:  3.1615e-01  3.1614e-01  7e-06  5e-10  4e-05\n",
      "10:  3.1615e-01  3.1615e-01  2e-07  6e-10  7e-07\n",
      "11:  3.1615e-01  3.1615e-01  9e-09  6e-10  1e-08\n",
      "Optimal solution found.\n",
      "accuracy on train : 0.966\n"
     ]
    }
   ],
   "source": [
    "print('train shape : {}'.format(X_raw1.shape))\n",
    "print('train shape 2 : {}'.format(Y1.shape))\n",
    "print('test shape : {}'.format(X_valid1.shape))\n",
    "\n",
    "Y_predict1 = solve_svm_test(X_raw1, \n",
    "                           X_valid1, \n",
    "                           Y1, \n",
    "                           kernel='diMismatch', \n",
    "                           k=7, m = 1,\n",
    "                           lamb=0.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (2000,)\n",
      "train shape 2 : (2000,)\n",
      "test shape : (1000,)\n",
      "building kernel...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.3960e+00  2.4334e+00  4e+03  1e+00  2e+05\n",
      " 1:  2.3332e+00 -7.2022e+01  8e+01  3e-02  5e+03\n",
      " 2:  1.6061e+00 -1.1866e+01  1e+01  4e-03  8e+02\n",
      " 3:  1.3364e+00 -9.8364e-01  2e+00  5e-04  8e+01\n",
      " 4:  7.9561e-01  3.3059e-01  5e-01  3e-05  4e+00\n",
      " 5:  4.7751e-01  4.0469e-01  7e-02  4e-06  7e-01\n",
      " 6:  4.3765e-01  4.2205e-01  2e-02  7e-07  1e-01\n",
      " 7:  4.2837e-01  4.2620e-01  2e-03  6e-08  1e-02\n",
      " 8:  4.2701e-01  4.2684e-01  2e-04  4e-09  7e-04\n",
      " 9:  4.2690e-01  4.2690e-01  9e-06  6e-10  3e-05\n",
      "10:  4.2690e-01  4.2690e-01  4e-07  7e-10  8e-07\n",
      "11:  4.2690e-01  4.2690e-01  1e-08  7e-10  1e-08\n",
      "Optimal solution found.\n",
      "accuracy on train : 0.899\n"
     ]
    }
   ],
   "source": [
    "print('train shape : {}'.format(X_raw2.shape))\n",
    "print('train shape 2 : {}'.format(Y2.shape))\n",
    "print('test shape : {}'.format(X_valid2.shape))\n",
    "\n",
    "Y_predict2 = solve_svm_test(X_raw2, \n",
    "                           X_valid2, \n",
    "                           Y2, \n",
    "                           kernel='k_gram_concat_several', \n",
    "                           k2=7, lamb=0.03, gamma=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test0 = Y_predict0[:][0]\n",
    "test1 = Y_predict1[:][0]\n",
    "test2 = Y_predict2[:][0]\n",
    "\n",
    "bound = np.concatenate((test0,test1,test2), axis=0).reshape((-1)).astype(int)\n",
    "final = pd.DataFrame(np.arange(3000), columns=['Id'])\n",
    "final['Bound'] = bound\n",
    "final.to_csv('resultk_6.csv', index= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id  Bound\n",
      "0        0      0\n",
      "1        1      1\n",
      "2        2      0\n",
      "3        3      0\n",
      "4        4      1\n",
      "5        5      1\n",
      "6        6      1\n",
      "7        7      0\n",
      "8        8      1\n",
      "9        9      0\n",
      "10      10      0\n",
      "11      11      0\n",
      "12      12      0\n",
      "13      13      0\n",
      "14      14      1\n",
      "15      15      1\n",
      "16      16      1\n",
      "17      17      1\n",
      "18      18      0\n",
      "19      19      0\n",
      "20      20      1\n",
      "21      21      1\n",
      "22      22      1\n",
      "23      23      0\n",
      "24      24      1\n",
      "25      25      0\n",
      "26      26      0\n",
      "27      27      0\n",
      "28      28      0\n",
      "29      29      0\n",
      "...    ...    ...\n",
      "2970  2970      0\n",
      "2971  2971      1\n",
      "2972  2972      1\n",
      "2973  2973      0\n",
      "2974  2974      0\n",
      "2975  2975      1\n",
      "2976  2976      1\n",
      "2977  2977      0\n",
      "2978  2978      1\n",
      "2979  2979      1\n",
      "2980  2980      0\n",
      "2981  2981      1\n",
      "2982  2982      1\n",
      "2983  2983      0\n",
      "2984  2984      0\n",
      "2985  2985      0\n",
      "2986  2986      0\n",
      "2987  2987      1\n",
      "2988  2988      0\n",
      "2989  2989      0\n",
      "2990  2990      0\n",
      "2991  2991      0\n",
      "2992  2992      0\n",
      "2993  2993      0\n",
      "2994  2994      0\n",
      "2995  2995      0\n",
      "2996  2996      0\n",
      "2997  2997      0\n",
      "2998  2998      1\n",
      "2999  2999      0\n",
      "\n",
      "[3000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check before submit if the final has good shape\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hackathon]",
   "language": "python",
   "name": "conda-env-hackathon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
