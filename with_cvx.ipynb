{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from numba import njit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from numpy import linalg as LA\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from sklearn import svm\n",
    "\n",
    "from kernel_functions import * # gram_phi, count_kuplet_k, count_kuplet_3\n",
    "from preprocessing import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sequences shape: ', (2000,))\n",
      "('sequence first row: ', 'TCCTCAACTTTTATTGGGCCGCTGTGGCACCAGAATCTACGAATGGCGCCCTCTAGAGTTGTGTAAAGAAGTGGCGTCACCTCATTATAAATAAAAGGTTG')\n",
      "('labels shape', (2000,))\n"
     ]
    }
   ],
   "source": [
    "# load all data as the numpy array type\n",
    "#X = pd.read_csv('data/Xtr1_mat50.csv', sep=' ', header=None).values\n",
    "X_raw0 = pd.read_csv('data/Xtr0.csv', sep= ' ', header = None).values.reshape((-1))\n",
    "X_raw1 = pd.read_csv('data/Xtr1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_raw2 = pd.read_csv('data/Xtr2.csv', sep=' ', header=None).values.reshape((-1))\n",
    "\n",
    "# transform to an array of string\n",
    "X_valid0 = pd.read_csv('data/Xte0.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_valid1 = pd.read_csv('data/Xte1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "X_valid2 = pd.read_csv('data/Xte1.csv', sep=' ', header=None).values.reshape((-1))\n",
    "\n",
    "\n",
    "Y0 = pd.read_csv('data/Ytr0.csv', sep=',', header=0)['Bound'].values\n",
    "Y1 = pd.read_csv('data/Ytr1.csv', sep=',', header=0)['Bound'].values\n",
    "Y2 = pd.read_csv('data/Ytr2.csv', sep=',', header=0)['Bound'].values\n",
    "\n",
    "#print('numerical features shape', X.shape)\n",
    "#print('numerical features first row', X[0])\n",
    "print('sequences shape: ', X_raw0.shape)\n",
    "print('sequence first row: ', X_raw0[0])\n",
    "print('labels shape', Y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernel import *\n",
    "import multiprocessing # import Pool\n",
    "\n",
    "\n",
    "def solve_svm_kernel(X_train, X_test, Y_train, Y_test, kernel='k_gram_gaussian', k=3, lamb=0.1, gamma=0.1, kktreg=1e-9):\n",
    "    \"\"\"\n",
    "    kernel in ['k_gram', 'k_gram_gaussian', 'k_substring', 'local_alignement']\n",
    "    \"\"\"\n",
    "    assert kernel in ['k_gram', 'k_gram_gaussian', 'k_substring', 'local_alignement']\n",
    "    \n",
    "    if kernel in ['k_gram', 'k_gram_gaussian']:\n",
    "        if k == 3:\n",
    "            X_train_process = np.array([count_kuplet_3(x) for x in X_train])\n",
    "            X_test_process = np.array([count_kuplet_3(x) for x in X_test])\n",
    "        else:\n",
    "            X_train_process = np.array([count_kuplet_k(x,k=k) for x in X_train])\n",
    "            X_test_process = np.array([count_kuplet_k(x,k=k) for x in X_test])\n",
    "        \n",
    "        # Adding 1 for the sake of the bias\n",
    "        X_train_process = np.concatenate((X_train_process, np.ones((X_train_process.shape[0], 1))), axis=1)\n",
    "        X_test_process = np.concatenate((X_test_process, np.ones((X_test_process.shape[0], 1))), axis=1)\n",
    "        \n",
    "    if kernel==\"k_gram\":\n",
    "        # Computing the Gram-Matrix\n",
    "        K = X_train_process.dot(X_train_process.T)\n",
    "        w = solve_svm(K, Y_train, lamb=lamb, kktreg=kktreg)\n",
    "        K_test = np.dot(X_test_process, np.transpose(X_train_process))\n",
    "        print(K_test.shape)\n",
    "    \n",
    "    if kernel==\"k_gram_gaussian\":\n",
    "        # Computing the Gram-Matrix\n",
    "        K = np.array([LA.norm(X_train_process - y, axis=1) for y in X_train_process])\n",
    "        K = np.exp(-K/gamma)\n",
    "        # K = X_train_process.dot(X_train_process.T)\n",
    "        w = solve_svm(K, Y_train, lamb=lamb)\n",
    "        K_test = np.array([LA.norm(X_train_process - y, axis=1) for y in X_test_process])\n",
    "        print(K_test.shape)\n",
    "        K_test = np.exp(-K_test/gamma)\n",
    "    \n",
    "    if kernel=='k_substring':\n",
    "        # Computing the Gram-Matrix\n",
    "        # X_train_process = X_train\n",
    "        # X_test_process = X_test\n",
    "        N_train = len(X_train)\n",
    "        N_test = len(X_test)\n",
    "        K = np.zeros((N_train, N_train))\n",
    "        for i in tqdm(range(len(X_train))):# ,desc=\"Computing Traning Kernel\":\n",
    "            # print(\"building pool\")\n",
    "            # pool = multiprocessing.Pool(4)\n",
    "            # print(\"build param\")\n",
    "            # param = [(X_train[i], X_train[j], k) for j in range(len(X_train))]\n",
    "            # print(\"using pool\")\n",
    "            # K[i][:] = pool.map(compute_gap_kernel_param, [[X_train[i], X_train[j], k] for j in range(len(X_train))])\n",
    "            # print(K_test[i][:])\n",
    "            for j in range(i, len(X_train)):\n",
    "                K[i][j] = K[j][i] = compute_gap_kernel(X_train[i], X_train[j], k)\n",
    "        w = solve_svm(K, Y_train, lamb=lamb, kktreg=kktreg)\n",
    "        K_test = np.zeros((N_test, N_train))\n",
    "        for i in tqdm(range(len(X_test)), desc=\"Compution testing Kernel\"):\n",
    "            for j in range(len(X_train)):\n",
    "                K_test[i][j] = compute_gap_kernel(X_test[i], X_train[j], k)\n",
    "    \n",
    "    if kernel=='local_alignement':\n",
    "        # Computing the Gram-Matrix\n",
    "        # X_train_process = X_train\n",
    "        # X_test_process = X_test\n",
    "        N_train = len(X_train)\n",
    "        N_test = len(X_test)\n",
    "        K = np.zeros((N_train, N_train))\n",
    "        for i in tqdm(range(len(X_train))):# ,desc=\"Computing Traning Kernel\":\n",
    "            # print(\"building pool\")\n",
    "            # pool = multiprocessing.Pool(4)\n",
    "            # print(\"build param\")\n",
    "            # param = [(X_train[i], X_train[j], k) for j in range(len(X_train))]\n",
    "            # print(\"using pool\")\n",
    "            # K[i][:] = pool.map(compute_gap_kernel_param, [[X_train[i], X_train[j], k] for j in range(len(X_train))])\n",
    "            # print(K_test[i][:])\n",
    "            for j in range(i, len(X_train)):\n",
    "                K[i][j] = K[j][i] = LA_kernel(X_train[i], X_train[j])\n",
    "        w = solve_svm(K, Y_train, lamb=lamb, kktreg=kktreg)\n",
    "        K_test = np.zeros((N_test, N_train))\n",
    "        for i in tqdm(range(len(X_test)), desc=\"Compution testing Kernel\"):\n",
    "            for j in range(len(X_train)):\n",
    "                K_test[i][j] = LA_kernel(X_test[i], X_train[j])\n",
    "                \n",
    "    # if kernel in ['k_gram', 'k_gram_gaussian']:\n",
    "    n = K.shape[0]\n",
    "    Y_predicted = np.dot(K_test, w[:n]) > 0.\n",
    "    result = ((Y_test+1.)/ 2. == np.transpose(Y_predicted))\n",
    "    Y_predicted_train = np.dot(K, w[:n]) > 0.\n",
    "    result_train = ((Y_train+1)/ 2 == np.transpose(Y_predicted_train))\n",
    "    print(Y_predicted)\n",
    "    if np.alltrue(Y_predicted):\n",
    "        print(\"Toute les valeurs sont TRUE\")\n",
    "    if np.alltrue(Y_predicted==False):\n",
    "        print(\"Toute les valeurs sont FALSE\")\n",
    "    return np.mean(result), np.mean(result_train)\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train shape', (1600,))\n",
      "('test shape', (400,))\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = preprocessing(X_raw1, Y1)\n",
    "print('train shape', X_train.shape)\n",
    "print('test shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GAGGGCCAGCTCCCGCACTAACAGAGTTGCTCTGCAGGGATGGTGCATAGCACAAAGAAAAGGTGATTTTGGCTGCAGAATTGAAAAACCATATGTATGGT'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009765625\n"
     ]
    }
   ],
   "source": [
    "def compute_gap_kernel(X1, X2, k, lamb=0.5):\n",
    "    N_X1 = len(X1)\n",
    "    N_X2 = len(X2)\n",
    "    B = np.zeros((k+1, N_X1+1, N_X2+1))\n",
    "    K = np.zeros((N_X1+1, N_X2+1))\n",
    "    ker = np.zeros(k+1)\n",
    "    for i in range(1, N_X1+1):\n",
    "        for j in range(1, N_X2+1):\n",
    "            if(X1[i-1] == X2[j-1]):\n",
    "                B[1, i, j] = lamb**2 \n",
    "                ker[1] += lamb**2 \n",
    "    # ker = ker/(lamb**2) # renormalize\n",
    "    for l in range(2, k+1):\n",
    "        for i in range(1, N_X1+1):\n",
    "            for j in range(1, N_X2+1):\n",
    "                K[i, j] = B[l-1, i, j] + lamb*K[i-1, j] + lamb*K[i, j-1] - (lamb**2)*K[i-1, j-1]\n",
    "                if X1[i-1]==X2[j-1]:\n",
    "                    B[l, i, j] = lamb**2 * K[i-1, j-1]\n",
    "                    ker[l] = ker[l] + B[l, i, j]\n",
    "    return ker[k]\n",
    "\n",
    "def compute_gap_kernel_param(param):\n",
    "    return compute_gap_kernel(param[0], param[1], param[2])\n",
    "\n",
    "X1 = 'CGGGGCA'\n",
    "X2 = 'CCAT'\n",
    "k = 3\n",
    "ker = compute_gap_kernel(X1, X2, k, lamb=0.5)\n",
    "# ker, B, K = compute_gap_kernel(X1, X2, 3, lamb=0.5)\n",
    "print(ker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train shape', (1600,))\n",
      "('test shape', (400,))\n",
      "('train shape', (1600,))\n",
      "('test shape', (400,))\n",
      "('train shape', (1600,))\n",
      "('test shape', (400,))\n"
     ]
    }
   ],
   "source": [
    "# With Cross validation\n",
    "\n",
    "X_train0, Y_train0, X_test0, Y_test0 = preprocessing(X_raw0, Y0)\n",
    "X_train1, Y_train1, X_test1, Y_test1 = preprocessing(X_raw1, Y1)\n",
    "X_train2, Y_train2, X_test2, Y_test2 = preprocessing(X_raw2, Y2)\n",
    "print('train shape', X_train0.shape)\n",
    "print('test shape', X_test0.shape)\n",
    "\n",
    "print('train shape', X_train1.shape)\n",
    "print('test shape', X_test1.shape)\n",
    "\n",
    "print('train shape', X_train2.shape)\n",
    "print('test shape', X_test2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:19<05:11,  6.62s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-b83545bc5b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                        \u001b[0mY_test0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                        \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'local_alignement'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                        k=3, lamb=0.001, gamma=5)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy for train : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_train0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-1e938c2f63f0>\u001b[0m in \u001b[0;36msolve_svm_kernel\u001b[0;34m(X_train, X_test, Y_train, Y_test, kernel, k, lamb, gamma, kktreg)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# print(K_test[i][:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLA_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkktreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkktreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mK_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-453407871a93>\u001b[0m in \u001b[0;36mLA_kernel\u001b[0;34m(u, v, d, e, beta)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_u\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_v\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-453407871a93>\u001b[0m in \u001b[0;36mS\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# def LA_kernel(X1, X2):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_test0, acc_train0 = solve_svm_kernel(X_train0[:50], \n",
    "                                       X_test0[:10], \n",
    "                                       Y_train0[:50], \n",
    "                                       Y_test0[:10], \n",
    "                                       kernel='local_alignement', \n",
    "                                       k=3, lamb=0.001, gamma=5)\n",
    "\n",
    "print('accuracy for train : {}'.format(acc_train0))\n",
    "print('accuracy for test : {}'.format(acc_test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.3586e-01  5.1306e+02  1e+04  3e+00  1e+06\n",
      " 1:  2.4435e+00 -1.5721e+02  2e+02  3e-02  2e+04\n",
      " 2:  2.3893e+00 -6.4279e+00  9e+00  2e-03  7e+02\n",
      " 3:  1.7351e+00 -2.8486e-01  2e+00  2e-04  9e+01\n",
      " 4:  6.6843e-01  4.2466e-01  2e-01  1e-05  5e+00\n",
      " 5:  5.6983e-01  4.9009e-01  8e-02  3e-06  1e+00\n",
      " 6:  5.4689e-01  5.0801e-01  4e-02  1e-06  6e-01\n",
      " 7:  5.3331e-01  5.1829e-01  2e-02  3e-07  2e-01\n",
      " 8:  5.2768e-01  5.2256e-01  5e-03  9e-08  4e-02\n",
      " 9:  5.2586e-01  5.2402e-01  2e-03  3e-08  1e-02\n",
      "10:  5.2510e-01  5.2461e-01  5e-04  1e-09  7e-04\n",
      "11:  5.2492e-01  5.2477e-01  2e-04  9e-10  1e-04\n",
      "12:  5.2485e-01  5.2483e-01  1e-05  1e-09  9e-06\n",
      "13:  5.2484e-01  5.2484e-01  3e-07  1e-09  2e-07\n",
      "14:  5.2484e-01  5.2484e-01  6e-09  1e-09  3e-09\n",
      "Optimal solution found.\n",
      "accuracy for train : 0.7875\n",
      "accuracy for test : 0.74\n"
     ]
    }
   ],
   "source": [
    "acc_test1, acc_train1 = solve_svm_kernel(X_train1, \n",
    "                                       X_test1, \n",
    "                                       Y_train1, \n",
    "                                       Y_test1, \n",
    "                                       kernel='k_gram', \n",
    "                                       k=3, lamb=0.01, gamma=1.)\n",
    "\n",
    "print('accuracy for train : {}'.format(acc_train1))\n",
    "print('accuracy for test : {}'.format(acc_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 1.  0.  1.  2.  3.  4.]\n",
      " [ 2.  1.  2.  3.  4.  3.]\n",
      " [ 3.  2.  3.  4.  5.  4.]\n",
      " [ 4.  3.  4.  5.  6.  5.]\n",
      " [ 5.  4.  5.  6.  5.  6.]\n",
      " [ 6.  5.  4.  5.  6.  7.]]\n"
     ]
    }
   ],
   "source": [
    "def edit_distance(str1, str2):\n",
    "    \"\"\"\n",
    "    Compute the Edit Distance between str1 and str2.\n",
    "    Return the number of insertion/deletion/substitution\n",
    "    \"\"\"\n",
    "    n = len(str1)\n",
    "    m = len(str2)\n",
    "    table_str = np.zeros((n+1,m+1))\n",
    "\n",
    "    table_str[0, :]=np.arange(m+1)\n",
    "    table_str[:, 0] = np.arange(n+1)\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            if(str1[i-1] == str2[j-1]):\n",
    "                table_str[i, j] = min(table_str[i-1, j] + 1, table_str[i, j-1] + 1, table_str[i-1, j-1]) \n",
    "            else:\n",
    "                table_str[i, j] = min(table_str[i-1, j] + 1, table_str[i, j-1] + 1, table_str[i-1, j-1]+2) \n",
    "                \n",
    "    return table_str\n",
    "\n",
    "X1 = 'ACCCTG'\n",
    "X2 = 'AGGTC'\n",
    "print(edit_distance(X1, X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.5414e-02  1.6000e-02  1e+00  1e+00  4e-08\n",
      " 1:  1.5994e-02  1.6000e-02  1e-02  1e-02  4e-10\n",
      " 2:  1.6000e-02  1.6000e-02  1e-04  1e-04  3e-12\n",
      " 3:  1.6000e-02  1.6000e-02  1e-06  1e-06  1e-13\n",
      " 4:  1.6000e-02  1.6000e-02  1e-08  1e-08  2e-15\n",
      "Optimal solution found.\n",
      "accuracy for train : 1.0\n",
      "accuracy for test : 0.5925\n"
     ]
    }
   ],
   "source": [
    "acc_test2, acc_train2 = solve_svm_kernel(X_train2, \n",
    "                                       X_test2, \n",
    "                                       Y_train2, \n",
    "                                       Y_test2, \n",
    "                                       kernel='k_gram_gaussian', \n",
    "                                       k=6, lamb=0.00001, gamma=1.)\n",
    "\n",
    "print('accuracy for train : {}'.format(acc_train2))\n",
    "print('accuracy for test : {}'.format(acc_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters found for k_gram kernel\n",
    "* Set0: lambda=1e-3, gamma = 5 (gaussian)\n",
    "* Set1: lambda=0.01\n",
    "* Set2: lambda= 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def solve_svm_test(X_train, X_test, Y_train, kernel='k_gram_gaussian', k=3, lamb=0.1, gamma=0.1, kktreg=1e-9):\n",
    "    \"\"\"\n",
    "    kernel in [k_gram, k_gram_gaussian]\n",
    "    \"\"\"\n",
    "    Y_train_process = (Y_train-0.5) * 2\n",
    "    if kernel in ['k_gram', 'k_gram_gaussian']:\n",
    "        if k == 3:\n",
    "            X_train_process = np.array([count_kuplet_3(x) for x in X_train])\n",
    "            X_test_process = np.array([count_kuplet_3(x) for x in X_test])\n",
    "        else:\n",
    "            X_train_process = np.array([count_kuplet_k(x,k=k) for x in X_train])\n",
    "            X_test_process = np.array([count_kuplet_k(x,k=k) for x in X_test])\n",
    "        \n",
    "        # Adding 1 for the sake of the bias\n",
    "        X_train_process = np.concatenate((X_train_process, np.ones((X_train_process.shape[0], 1))), axis=1)\n",
    "        X_test_process = np.concatenate((X_test_process, np.ones((X_test_process.shape[0], 1))), axis=1)\n",
    "        \n",
    "        \n",
    "    if kernel==\"k_gram\":\n",
    "        # Computing the Gram-Matrix\n",
    "        K = X_train_process.dot(X_train_process.T)\n",
    "        w = solve_svm(K, Y_train_process, lamb=lamb, kktreg=kktreg)\n",
    "        K_test = np.dot(X_test_process, np.transpose(X_train_process))\n",
    "    \n",
    "    if kernel==\"k_gram_gaussian\":\n",
    "        # Computing the Gram-Matrix\n",
    "        K = np.array([LA.norm(X_train_process - y, axis=1) for y in X_train_process])\n",
    "        K = np.exp(-K/gamma)\n",
    "        # K = X_train_process.dot(X_train_process.T)\n",
    "        w = solve_svm(K, Y_train_process, lamb=lamb)\n",
    "        K_test = np.array([LA.norm(X_train_process - y, axis=1) for y in X_test_process])\n",
    "        K_test = np.exp(-K_test/gamma)\n",
    "    \n",
    "    n = K.shape[0]\n",
    "    Y_predicted = np.dot(K_test, w[:n]) > 0.\n",
    "    Y_predicted = (Y_predicted + 0.)\n",
    "    Y_predicted_train = np.dot(K, w[:n]) > 0.\n",
    "    result_train = (Y_train == np.transpose(Y_predicted_train))\n",
    "    print('accuracy on train : {}'.format(np.mean(result_train)))\n",
    "    # result = ((Y_test+1)/ 2 == np.transpose(Y_predicted))\n",
    "    \n",
    "    return np.transpose(Y_predicted) # , np.transpose(Y_predicted_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (2000,)\n",
      "train shape 2 : (2000,)\n",
      "test shape : (1000,)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.9546e+00  2.9746e+00  4e+03  1e+00  2e+02\n",
      " 1:  2.9161e+00 -5.7463e+01  6e+01  2e-02  2e+00\n",
      " 2:  2.0943e+00 -9.6812e+00  1e+01  4e-03  4e-01\n",
      " 3:  1.5247e+00  2.3207e-01  1e+00  2e-04  2e-02\n",
      " 4:  8.5340e-01  7.5174e-01  1e-01  6e-07  7e-05\n",
      " 5:  8.0636e-01  7.8541e-01  2e-02  1e-07  1e-05\n",
      " 6:  7.9629e-01  7.9397e-01  2e-03  7e-09  8e-07\n",
      " 7:  7.9516e-01  7.9504e-01  1e-04  6e-10  3e-08\n",
      " 8:  7.9510e-01  7.9510e-01  3e-06  7e-10  6e-10\n",
      " 9:  7.9510e-01  7.9510e-01  6e-08  7e-10  1e-11\n",
      "Optimal solution found.\n",
      "accuracy on train : 0.861\n"
     ]
    }
   ],
   "source": [
    "print('train shape : {}'.format(X_raw0.shape))\n",
    "print('train shape 2 : {}'.format(Y0.shape))\n",
    "print('test shape : {}'.format(X_valid0.shape))\n",
    "\n",
    "Y_predict0 = solve_svm_test(X_raw0, \n",
    "                           X_valid0, \n",
    "                           Y0, \n",
    "                           kernel='k_gram_gaussian', \n",
    "                           k=3, lamb=.001, gamma=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (2000,)\n",
      "train shape 2 : (2000,)\n",
      "test shape : (1000,)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.3956e-01  6.5897e+02  2e+04  3e+00  2e+06\n",
      " 1:  2.5257e+00 -2.0302e+02  2e+02  3e-02  2e+04\n",
      " 2:  2.4864e+00 -9.2458e+00  1e+01  2e-03  8e+02\n",
      " 3:  1.9470e+00 -6.7863e-01  3e+00  2e-04  1e+02\n",
      " 4:  7.4528e-01  4.4086e-01  3e-01  2e-07  1e-01\n",
      " 5:  5.8324e-01  5.1002e-01  7e-02  5e-08  2e-02\n",
      " 6:  5.6350e-01  5.2487e-01  4e-02  2e-08  1e-02\n",
      " 7:  5.5168e-01  5.3334e-01  2e-02  8e-09  4e-03\n",
      " 8:  5.4558e-01  5.3790e-01  8e-03  3e-09  2e-03\n",
      " 9:  5.4284e-01  5.3994e-01  3e-03  9e-10  4e-04\n",
      "10:  5.4164e-01  5.4090e-01  7e-04  1e-09  6e-05\n",
      "11:  5.4137e-01  5.4113e-01  2e-04  1e-09  9e-06\n",
      "12:  5.4127e-01  5.4122e-01  5e-05  1e-09  2e-06\n",
      "13:  5.4125e-01  5.4124e-01  9e-06  1e-09  3e-07\n",
      "14:  5.4124e-01  5.4124e-01  9e-07  1e-09  2e-08\n",
      "15:  5.4124e-01  5.4124e-01  2e-08  1e-09  3e-10\n",
      "Optimal solution found.\n",
      "accuracy on train : 0.772\n"
     ]
    }
   ],
   "source": [
    "print('train shape : {}'.format(X_raw1.shape))\n",
    "print('train shape 2 : {}'.format(Y1.shape))\n",
    "print('test shape : {}'.format(X_valid1.shape))\n",
    "\n",
    "Y_predict1 = solve_svm_test(X_raw1, \n",
    "                           X_valid1, \n",
    "                           Y1, \n",
    "                           kernel='k_gram', \n",
    "                           k=3, lamb=0.01, gamma=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (2000,)\n",
      "train shape 2 : (2000,)\n",
      "test shape : (1000,)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.3222e-01  8.6743e+02  2e+04  3e+00  3e+05\n",
      " 1:  2.5361e+00 -1.7225e+02  2e+02  3e-02  3e+03\n",
      " 2:  2.5071e+00 -3.5663e+00  6e+00  7e-04  8e+01\n",
      " 3:  1.5970e+00  4.2108e-01  1e+00  6e-05  6e+00\n",
      " 4:  8.3534e-01  6.7856e-01  2e-01  8e-06  8e-01\n",
      " 5:  7.7959e-01  7.3967e-01  4e-02  2e-06  2e-01\n",
      " 6:  7.6658e-01  7.5337e-01  1e-02  4e-07  4e-02\n",
      " 7:  7.6288e-01  7.5704e-01  6e-03  2e-07  2e-02\n",
      " 8:  7.6102e-01  7.5887e-01  2e-03  4e-08  4e-03\n",
      " 9:  7.6032e-01  7.5955e-01  8e-04  1e-08  1e-03\n",
      "10:  7.6008e-01  7.5977e-01  3e-04  3e-09  3e-04\n",
      "11:  7.5996e-01  7.5989e-01  7e-05  8e-10  6e-05\n",
      "12:  7.5993e-01  7.5991e-01  2e-05  9e-10  1e-05\n",
      "13:  7.5992e-01  7.5992e-01  5e-06  1e-09  1e-06\n",
      "14:  7.5992e-01  7.5992e-01  5e-07  1e-09  1e-07\n",
      "15:  7.5992e-01  7.5992e-01  5e-09  1e-09  2e-09\n",
      "Optimal solution found.\n",
      "accuracy on train : 0.665\n"
     ]
    }
   ],
   "source": [
    "print('train shape : {}'.format(X_raw2.shape))\n",
    "print('train shape 2 : {}'.format(Y2.shape))\n",
    "print('test shape : {}'.format(X_valid2.shape))\n",
    "\n",
    "Y_predict2 = solve_svm_test(X_raw2, \n",
    "                           X_valid2, \n",
    "                           Y2, \n",
    "                           kernel='k_gram', \n",
    "                           k=3, lamb=1e-5, gamma=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test0 = Y_predict0[:][0]\n",
    "test1 = Y_predict1[:][0]\n",
    "test2 = Y_predict2[:][0]\n",
    "\n",
    "bound = np.concatenate((test0,test1,test2), axis=1).reshape((-1)).astype(int)\n",
    "final = pd.DataFrame(np.arange(3000), columns=['Id'])\n",
    "final['Bound'] = bound\n",
    "final.to_csv('result0.csv', index= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check before submit if the final has good shape\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
